<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Relative contributions of antimicrobial use and external contaminations on colistin resistance in Mekong delta chicken farms</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="site_libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>
<link href="site_libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="site_libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="site_libs/plotly-main-1.46.1/plotly-latest.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Colistin resistance</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Overview</a>
</li>
<li>
  <a href="make_data.html">Data generation</a>
</li>
<li>
  <a href="Analysis_col_res.html">Model</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Relative contributions of antimicrobial use and external contaminations on colistin resistance in Mekong delta chicken farms</h1>

</div>


<!--
IMAGES:
Insert them with: ![alt text](image.png)
You can also resize them if needed: convert image.png -resize 50% image.png
If you want to center the image, go through HTML code:
<div style="text-align:center"><img src ="image.png"/></div>

REFERENCES:
For references: Put all the bibTeX references in the file "references.bib"
in the current folder and cite the references as @key or [@key] in the text.
Uncomment the bibliography field in the above header and put a "References"
title wherever you want to display the reference list.
-->
<style type="text/css">
.main-container {
  max-width: 1370px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<p>The objective is to understand the relative contributions of different factors to the colistin resistance detected in samples from ViParc chicken farms:</p>
<ul>
<li>antimicrobial use (AMU)</li>
<li>the carriage of colistin resistance in day-old chicks</li>
<li>introductions of resistant strains from outside the flock (other flocks, environment, human-poultry transmission)</li>
</ul>
<p>Available data is:</p>
<ul>
<li>Data on ViParc farms, including AMU and sampling dates: <a href="https://rpubs.com/choisy/viparc_data">ViParc data overview</a>.</li>
<li>During each production cycle, 3 (or less) pooled chicken faeces samples are collected: at the beginning, in the middle and at the end of the cycle. Around 30 E.coli colonies are collected from each sample and pooled. The Optical Density of each of these pooled samples is measured twice to obtain their growth curve in presence of different colistin concentrations. For each sample, the MIC can be determined from these growth curves.</li>
</ul>
<p>We first clean work environment and load needed packages.</p>
<pre class="r"><code>&gt; rm(list=ls(all=TRUE))
&gt; 
&gt; library(deSolve)
Warning: package &#39;deSolve&#39; was built under R version 3.4.4
&gt; library(bbmle)
Warning: package &#39;bbmle&#39; was built under R version 3.4.4
Loading required package: stats4
&gt; library(ggplot2)
&gt; library(grid)
&gt; library(reshape2)
Warning: package &#39;reshape2&#39; was built under R version 3.4.4
&gt; library(readxl)
Warning: package &#39;readxl&#39; was built under R version 3.4.4
&gt; library(pracma)

Attaching package: &#39;pracma&#39;
The following object is masked from &#39;package:deSolve&#39;:

    rk4
&gt; library(agrmt)
Warning: package &#39;agrmt&#39; was built under R version 3.4.4
&gt; library(shiny)
Warning: package &#39;shiny&#39; was built under R version 3.4.4
&gt; library(parallel)
&gt; library(plotly)
Warning: package &#39;plotly&#39; was built under R version 3.4.4

Attaching package: &#39;plotly&#39;
The following object is masked from &#39;package:ggplot2&#39;:

    last_plot
The following object is masked from &#39;package:bbmle&#39;:

    slice
The following object is masked from &#39;package:stats&#39;:

    filter
The following object is masked from &#39;package:graphics&#39;:

    layout</code></pre>
<div id="data" class="section level1">
<h1>Data</h1>
<div id="load-data" class="section level2">
<h2>Load data</h2>
<p>We load data:</p>
<ul>
<li><code>viparc_data_quali</code> and <code>viparc_data_quanti</code>: Includes production cycles, AMU (resp. qualitative and quantitative), sampling dates in ViParc farms.</li>
<li><code>gcur</code>: Optical density (growth curves) measured in the samples at different times, at different colistin concentrations</li>
<li><code>mic_data</code>: MIC for each sample</li>
</ul>
<pre class="r"><code>&gt; # viparc_data_quali = read.csv(&quot;https://raw.githubusercontent.com/viparc/colistin_resistance/master/data/viparc_qualitative.csv&quot;)
&gt; # viparc_data_quanti = read.csv(&quot;https://raw.githubusercontent.com/viparc/colistin_resistance/master/data/viparc_quantitative.csv&quot;)
&gt; 
&gt; viparc_data_quali = read.csv(&quot;C:/Users/Jonathan/Desktop/Programmes/colistin_resistance/viparc_qualitative.csv&quot;)
&gt; viparc_data_quanti = read.csv(&quot;C:/Users/Jonathan/Desktop/Programmes/colistin_resistance/viparc_quantitative.csv&quot;)
&gt; 
&gt; mic_data = as.data.frame(read_excel(path=&quot;C:/Users/Jonathan/Desktop/Programmes/colistin_resistance/ColR_MIC.xlsx&quot;, sheet=&quot;MIC data&quot;))
&gt; mic_data$MIC = as.numeric(mic_data$MIC)
Warning: NAs introduits lors de la conversion automatique
&gt; mic_data = dcast(mic_data, ID + FarmID + Flockseq ~ SamplingPoint, value.var=&quot;MIC&quot;)
&gt; mic_data = mic_data[, c(&quot;ID&quot;, &quot;FarmID&quot;, &quot;Flockseq&quot;, &quot;Start&quot;, &quot;Mid&quot;, &quot;End&quot;)]
&gt; 
&gt; gcur = as.data.frame(read_excel(path=&quot;C:/Users/Jonathan/Desktop/Programmes/colistin_resistance/ColR_MIC.xlsx&quot;, sheet=&quot;OD&quot;))
&gt; 
&gt; id_matrix = mic_data[,c(&quot;ID&quot;, &quot;FarmID&quot;, &quot;Flockseq&quot;)]</code></pre>
</div>
<div id="choose-type-of-resistance-data-growth-curves-or-mic" class="section level2">
<h2>Choose type of resistance data: growth curves or MIC</h2>
<p>Here, we decide which resistance data we analyze: “growth_curves” or “mic”. The final object for resistance data will be <code>res_data</code>, with values ranging between 0 (lowest observed resistance) and 1 (highest observed resistance).</p>
<pre class="r"><code>&gt; type_res_data = &quot;growth_curves&quot;</code></pre>
<pre class="r"><code>&gt; if(type_res_data == &quot;mic&quot;){
+   res_data = mic_data[,c(&quot;Start&quot;, &quot;Mid&quot;, &quot;End&quot;)]
+   rownames(res_data) = mic_data$ID
+   colnames(res_data) = c(&quot;S&quot;, &quot;M&quot;, &quot;E&quot;)
+   res_data = (res_data - min(res_data, na.rm=T))/(max(res_data, na.rm=T) - min(res_data, na.rm=T))
+ }</code></pre>
</div>
<div id="resistance-data-determine-which-optical-density-dataset-to-use" class="section level2">
<h2>Resistance data: determine which Optical Density dataset to use</h2>
<p>This part is computed only in the case we chose growth curves as a measure of resistance in samples. We use <code>gcur</code>. Let us first plot the growth curves for each concentration. We remove concentrations 3 and 6, as too few OD were measured for these concentrations.</p>
<pre class="r"><code>&gt; if(type_res_data == &quot;growth_curves&quot;){
+   
+   gcur = melt(gcur, id.vars = c(&quot;SampleID&quot;, &quot;Conc.&quot;, &quot;FlockID&quot;, &quot;SamplPoint&quot;, &quot;Repeat&quot;), variable.name = &quot;Time&quot;)
+   gcur$Time = as.numeric(gcur$Time)
+   
+   # Unique ID for each observed curve:
+   gcur$obsID = paste0(gcur$SampleID, gcur$Repeat)
+   
+   # Remove concentrations 3 and 6:
+   gcur = gcur[which(!gcur$Conc. %in% c(3, 6)),]
+   
+   p = ggplot(data = gcur, aes(x=Time, group=obsID))
+   p = p + ggtitle(&quot;Optical Density in all samples for each concentration (in mg/L)&quot;)
+   p = p + xlab(&quot;Time (hours)&quot;) + ylab(&quot;OD (optical density)&quot;)
+   p = p + geom_line(aes(y=value), col=&quot;grey&quot;)
+   p = p + facet_wrap(~Conc.)
+   plot(p)
+   
+   rm(p)
+ }</code></pre>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-5-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Our objective is to use a concentration that offers a distribution of areas under curve (AUC) as spread out as possible. We see that, in concentrations 0 and 0.5, no curve is totally flat, i.e. all samples show some growth. On the contrary, in concentrations 8, 12 and 16, most of the samples show no growth. Therefore, we need to choose between concentrations 1, 2 and 4, that all present a spread range of curves (and thus AUC).</p>
<p>For these concentrations (1, 2 and 4), we compute the area under curve (AUC), for each sample, between t=15 hours and t=50 hours. This corresponds to the moment curves start to grow.</p>
<p>To measure how much the distributions of AUC are spread out for each concentration, we use the <a href="https://en.wikipedia.org/wiki/Multimodal_distribution#van_der_Eijk&#39;s_A">“van der Eijk’s A” statistic</a>. It ranges between -1 (perfect bimodality of the distribution) to +1 (perfect unimodality). A value of 0 corresponds to a uniform distribution. We select the concentration for which this statistic is closest to 0, because we aim to have both a spread distribution, and intermediary values of AUC (between high AUC - resistant samples - and low AUC - not resistant samples). We use package <code>agrmt</code>.</p>
<pre class="r"><code>&gt; if(type_res_data == &quot;growth_curves&quot;){
+   
+   VdE_A_score = function(conc, t_start, t_end){
+     
+     all_auc = c()
+     for(ts in unique(gcur$obsID)){
+       if(length(seq(t_start,t_end)) == length(gcur$value[which((gcur$Time %in% seq(t_start,t_end)) &amp; (gcur$Conc. == conc) &amp; (gcur$obsID == ts))])){
+         all_auc = c(all_auc, trapz(x = seq(t_start,t_end), y = gcur$value[which((gcur$Time %in% seq(t_start,t_end)) &amp; (gcur$Conc. == conc) &amp; (gcur$obsID == ts))]))
+       }else{
+         print(paste0(&quot;Problematic number of repetitions for obsID=&quot;, ts, &quot; (concentration &quot;, conc, &quot;).&quot;))
+       }
+     }
+     
+     list(agreement(table(factor(round(all_auc)))), all_auc)
+   }
+   
+   distrib_auc = data.frame(conc = numeric(0), val = numeric(0))
+   for(c in c(1, 2, 4)){
+     print(paste(&quot;van der Eijk&#39;s A for concentration&quot;, c, &quot;:&quot;))
+     VdE_A = VdE_A_score(conc=c, t_start=15, t_end=50)
+     print(VdE_A[[1]])
+     distrib_auc = rbind(distrib_auc, data.frame(conc = c, val = VdE_A[[2]]))
+   }
+   
+   # Plot distributions of AUC:
+   p = ggplot(data = distrib_auc, aes(x = val))
+   p = p + geom_histogram(bins = 15, fill = &quot;royalblue4&quot;)
+   p = p + facet_wrap(~conc)
+   p = p + ggtitle(&quot;Distribution of AUC values for each concentration (in mg/L)&quot;)
+   p = p + xlab(&quot;AUC values&quot;) + ylab(&quot;Count&quot;)
+   plot(p)
+   
+   rm(c, VdE_A_score, distrib_auc, VdE_A, p)
+ }
[1] &quot;van der Eijk&#39;s A for concentration 1 :&quot;
[1] 0.2703241
[1] &quot;van der Eijk&#39;s A for concentration 2 :&quot;
[1] 0.3869435
[1] &quot;van der Eijk&#39;s A for concentration 4 :&quot;
[1] 0.5430522</code></pre>
<p><img src="Analysis_col_res_files/figure-html/Calculating van der Eijk's A-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>We therefore select concentration 1. We average the 2 repetitions of a same sample, and reshape the data to obtain <code>auc_ob</code>. We standardize the AUC values to range between 0 (lowest value) and 1 (highest value).</p>
<pre class="r"><code>&gt; if(type_res_data == &quot;growth_curves&quot;){
+   
+   gcur = gcur[which(gcur$Conc. == 1),]
+   
+   gcur = dcast(gcur, SampleID + Conc. + FlockID + SamplPoint + Time ~ Repeat, value.var=&quot;value&quot;)
+   gcur$od = (gcur$`1` + gcur$`2`)/2
+   gcur = gcur[,c(&quot;SampleID&quot;, &quot;Conc.&quot;, &quot;FlockID&quot;, &quot;SamplPoint&quot;, &quot;Time&quot;, &quot;od&quot;)]
+   
+   auc_ob = as.data.frame(matrix(NA, nrow = length(unique(gcur$FlockID)), ncol = length(unique(gcur$SamplPoint))))
+   dimnames(auc_ob) = list(unique(gcur$FlockID), c(&quot;S&quot;, &quot;M&quot;, &quot;E&quot;))
+   for(flo in unique(gcur$FlockID)){
+     for(sp in unique(gcur$SamplPoint)){
+       if(length(15:50) == length(gcur$od[which((gcur$Time %in% (15:50)) &amp; (gcur$FlockID == flo) &amp; (gcur$SamplPoint == sp))])){
+         auc_ob[flo, sp] = trapz(x = 15:50, y = gcur$od[which((gcur$Time %in% (15:50)) &amp; (gcur$FlockID == flo) &amp; (gcur$SamplPoint == sp))])
+       }else{
+         print(paste0(&quot;Impossible to compute area under curve for flock &quot;, flo, &quot;, sampling point &quot;, sp))
+       }
+     }
+   }
+   
+   auc_ob = (auc_ob - min(auc_ob, na.rm=T))/(max(auc_ob, na.rm=T) - min(auc_ob, na.rm=T))
+   
+   # auc_ob = auc_ob[which(! rownames(auc_ob) %in% c(&quot;0351&quot;, &quot;0381&quot;, &quot;0391&quot;, &quot;0765&quot;)),]
+   # mic_data = mic_data[which(! mic_data$ID %in% c(&quot;0351&quot;, &quot;0381&quot;, &quot;0391&quot;, &quot;0765&quot;)),]
+   
+   res_data = auc_ob
+ 
+   rm(flo, sp, auc_ob)
+ }
[1] &quot;Impossible to compute area under curve for flock 0351, sampling point S&quot;
[1] &quot;Impossible to compute area under curve for flock 0381, sampling point S&quot;
[1] &quot;Impossible to compute area under curve for flock 0391, sampling point S&quot;
[1] &quot;Impossible to compute area under curve for flock 0765, sampling point S&quot;
[1] &quot;Impossible to compute area under curve for flock 0771, sampling point M&quot;</code></pre>
<p>No matters if the resistance metric we chose is “growth_curves” or “mic”, the measure is between 0 (lowest resistance) and 1 (highest resistance). We print the first rows of the resistance dataset <code>res_data</code>:</p>
<pre class="r"><code>&gt; print(head(res_data))
              S          M          E
0023 0.02890781 0.03158719 0.00000000
0062 0.08310251 0.13923266 0.14943835
0082 0.15543393 0.58010234 0.04345099
0211 0.05647176 0.67356172 0.58972241
0271 0.78480072 0.79651454 0.03022667
0351         NA 0.07282183 0.08235857
&gt; rm(type_res_data, mic_data)</code></pre>
</div>
<div id="antimicrobial-use-and-sampling-times" class="section level2">
<h2>Antimicrobial use and sampling times</h2>
<p>AMU is observed on a weekly basis. The molecules used are recorded either in a qualitative (use / no use) or quantitave (mg used /kg of chicken on farm) format. We create matrixes containing AMU for each week (columns) of the production cycle and for each cycle (rows):</p>
<ul>
<li><code>col_expo</code>: qualitative (yes/no) colistin use</li>
<li><code>col_expo_quanti</code>: quantitative (mg/kg) colistin use</li>
<li><code>allab_expo</code>: qualitative (yes/no) use of any antibiotic (including colistin)</li>
<li><code>allab_expo_quanti</code>: quantitative (mg/kg) use of all antibiotics (including colistin). We sum the quantity used for each antibiotic. An other option would be to take the maximum quantity used.</li>
</ul>
<p>We specify that we include all antibiotics in the <code>all_ab</code> category:</p>
<pre class="r"><code>&gt; all_ab = colnames(viparc_data_quali)[10:54]</code></pre>
<p>We define <code>n_cyc</code>, number of cycles included in the analysis, and n_samp, number of sampling times (3 in the study):</p>
<pre class="r"><code>&gt; n_cyc = nrow(res_data)
&gt; n_samp = 3</code></pre>
<p>We also define <code>weeks_samp</code>, matrix <code>n_cyc</code>*<code>n_samp</code>, that indicates the week of samplings for each cycle. <code>n_weeks</code> is the maximum number of production weeks among cycles included in the study. <code>init_flock_size</code> is the initial flock size for each cycle included (not used for now).</p>
<pre class="r"><code>&gt; col_expo = allab_expo = matrix(NA, n_cyc, max(viparc_data_quali$week))
&gt; col_expo_quanti = allab_expo_quanti = matrix(NA, n_cyc, max(viparc_data_quanti$week))
&gt; weeks_samp = matrix(NA, n_cyc, n_samp)
&gt; init_flock_size = rep(NA, n_cyc)
&gt; rownames(col_expo) = rownames(col_expo_quanti) = rownames(allab_expo) = rownames(allab_expo_quanti) = rownames(weeks_samp) = names(init_flock_size) = rownames(res_data)
&gt; 
&gt; for(i in 1:n_cyc){
+   farm_i = id_matrix$FarmID[i]
+   flockseq_i = id_matrix$Flockseq[i]
+   
+   if(!(any(viparc_data_quali$completed[which((viparc_data_quali$farm == farm_i)&amp;(viparc_data_quali$flock == flockseq_i))]) == T)){
+     print(paste0(&quot;For farm &quot;,farm_i,&quot;, flock sequence &quot;,flockseq_i,&quot;, the production cycle was not completed&quot;))
+   }
+   
+   # Colistin use (qualitative and quantitative):
+   
+   weeks_col_use = viparc_data_quali$week[which((viparc_data_quali$farm == farm_i)&amp;(viparc_data_quali$flock == flockseq_i)&amp;(viparc_data_quali[,&quot;colistin_use&quot;] == T))]
+   
+   weeks_col_no_use = viparc_data_quali$week[which((viparc_data_quali$farm == farm_i)&amp;(viparc_data_quali$flock == flockseq_i)&amp;(viparc_data_quali[,&quot;colistin_use&quot;] == F))]
+   
+   col_expo[i, weeks_col_use] = 1
+   col_expo[i, weeks_col_no_use] = col_expo_quanti[i, weeks_col_no_use] = 0
+   
+   # Quantitative colistin use
+   for(wk in weeks_col_use){
+     col_expo_quanti[i, wk] = 1000 * viparc_data_quanti[which((viparc_data_quanti$farm == farm_i)&amp;(viparc_data_quanti$flock == flockseq_i)&amp;(viparc_data_quanti$week == wk)), which(colnames(viparc_data_quali) == &quot;colistin_use&quot;)]
+   }
+   
+   # All antibiotics use (qualitative and quantitative):
+   
+   weeks_allab_use = viparc_data_quali$week[which((viparc_data_quali$farm == farm_i)&amp;(viparc_data_quali$flock == flockseq_i)&amp;(rowSums(viparc_data_quali[,all_ab], na.rm=T) != 0))]
+   
+   weeks_allab_no_use = viparc_data_quali$week[which((viparc_data_quali$farm == farm_i)&amp;(viparc_data_quali$flock == flockseq_i)&amp;(rowSums(viparc_data_quali[,all_ab], na.rm=T) == 0))]
+     
+   allab_expo[i, weeks_allab_use] = 1
+   allab_expo[i, weeks_allab_no_use] = allab_expo_quanti[i, weeks_allab_no_use] = 0
+   
+   # Quantitative [all antibiotics] use
+   for(wk in weeks_allab_use){
+     allab_expo_quanti[i, wk] = 1000 * sum(viparc_data_quanti[which((viparc_data_quanti$farm == farm_i)&amp;(viparc_data_quanti$flock == flockseq_i)&amp;(viparc_data_quanti$week == wk)), which(colnames(viparc_data_quali) %in% all_ab)])
+   }
+   
+   # Weeks of sampling:
+   
+   weeks_samp[i,] = viparc_data_quali$week[which((viparc_data_quali$farm == farm_i)&amp;(viparc_data_quali$flock == flockseq_i)&amp;(viparc_data_quali$sampling == T))]
+   
+   # Initial flock size:
+   
+   init_flock_size[i] = viparc_data_quali$nb_chicken[which((viparc_data_quali$farm == farm_i)&amp;(viparc_data_quali$flock == flockseq_i)&amp;(viparc_data_quali$week == 1))]
+ }
&gt; 
&gt; weeks_to_keep = which((colSums(!is.na(col_expo)) != 0) &amp; (colSums(!is.na(allab_expo)) != 0))
&gt; 
&gt; col_expo = col_expo[,weeks_to_keep]
&gt; col_expo_quanti = col_expo_quanti[,weeks_to_keep]
&gt; allab_expo = allab_expo[,weeks_to_keep]
&gt; allab_expo_quanti = allab_expo_quanti[,weeks_to_keep]
&gt; 
&gt; n_weeks = max(weeks_to_keep)
&gt; 
&gt; if(any(col_expo != (col_expo_quanti !=0), na.rm=T) | any(allab_expo != (allab_expo_quanti !=0), na.rm=T)){print(&quot;ERROR: Qualitative and quantitative AMU data are not consistent.&quot;)}
&gt; 
&gt; rm(i, wk, weeks_col_use, weeks_col_no_use, weeks_allab_use, weeks_allab_no_use, farm_i, flockseq_i, weeks_to_keep, all_ab, viparc_data_quali, viparc_data_quanti, id_matrix, n_samp, init_flock_size)</code></pre>
</div>
</div>
<div id="visualization" class="section level1">
<h1>Visualization</h1>
<div id="production-cycles-amu-and-sampling-dates" class="section level2">
<h2>Production cycles, AMU and sampling dates</h2>
<p>We plot the AMU and sampling dates for the <code>n_cyc</code> cycles. We also plot an example of the growth curves available for each sample, and the area under curve.</p>
<pre class="r"><code>&gt; plot(x=c(0,0.1), y=c(0,0), xlim=c(0,ncol(col_expo)+5), ylim=c(0,n_cyc+10), type=&quot;l&quot;, xlab=&quot;Weeks&quot;, ylab=&quot;&quot;, axes=F)
&gt; axis(side = 1)
&gt; title(ylab=&quot;Cycles&quot;, mgp=c(0,1,0))
&gt; 
&gt; for (i in 1:n_cyc){
+   
+   rect(xleft = 0.5, xright = 0.5+max(which(! is.na(col_expo[i,]))), ybottom = i-0.5, ytop = i+0.5, col = &quot;bisque&quot;, border=&quot;bisque&quot;)
+   
+   for (j in 1:ncol(col_expo)){
+     
+     if ((!(is.na(col_expo[i,j]))) &amp; (col_expo[i,j] == 1) &amp; (allab_expo[i,j] == 1)){
+       rect(xleft = j-0.5, xright = j+0.5, ybottom = i-0.5, ytop = i+0.5, col = &quot;coral3&quot;, border=&quot;coral3&quot;)
+     }else if ((!(is.na(col_expo[i,j]))) &amp; (col_expo[i,j] == 0) &amp; (allab_expo[i,j] == 1)){
+       rect(xleft = j-0.5, xright = j+0.5, ybottom = i-0.5, ytop = i+0.5, col = &quot;deepskyblue4&quot;, border=&quot;deepskyblue4&quot;)
+     }
+ 
+     if (any(weeks_samp[i,] == j, na.rm=T)){
+       rect(xleft = j-0.1, xright = j+0.1, ybottom = i-0.5, ytop = i+0.5, col = &quot;black&quot;, border=&quot;black&quot;)
+     }
+   }
+   lines(x = c(0.5, 0.5+max(which(! is.na(col_expo[i,])))), y = c(i-0.5, i-0.5), col=&quot;grey&quot;)
+   lines(x = c(0.5, 0.5+max(which(! is.na(col_expo[i,])))), y = c(i+0.5, i+0.5), col=&quot;grey&quot;)
+ }
&gt; 
&gt; legend(x=0, y=n_cyc+7, inset=0.5, legend=c(&quot;No antimicrobials used&quot;, &quot;Antimicrobials used, including colistin&quot;, &quot;Non-colistin antimicrobials used&quot;), fill=c(&quot;bisque&quot;, &quot;coral3&quot;, &quot;deepskyblue4&quot;), cex = 0.8, bty = &quot;n&quot;)
&gt; 
&gt; 
&gt; # 18th line starting from above
&gt; p2 = ggplot(data = gcur[(gcur$SampleID == &quot;0681E&quot;),], aes(x=Time, y=od))
&gt; p2 = p2 + xlab(&quot;Time (hours)&quot;) + ylab(&quot;OD&quot;)
&gt; p2 = p2 + geom_ribbon(aes(x=ifelse((Time&gt;15 &amp; Time&lt;=50), Time, 50), ymin=0, ymax=ifelse((Time&gt;15 &amp; Time&lt;=50), od, od[Time==50])), alpha=1, fill=&quot;chartreuse4&quot;)
&gt; p2 = p2 + geom_line(col=&quot;black&quot;, size=1)
&gt; 
&gt; print(p2, vp=viewport(width = 0.205, height = 0.275, x = 0.94, y = 0.39, just = c(&quot;right&quot;, &quot;bottom&quot;)))
&gt; 
&gt; rect(xleft=23, xright=31, ybottom=10, ytop=23, lwd=2)
&gt; lines(x=c(weeks_samp[&quot;0681&quot;,3], 23), y=c(18, 17), lwd=2)</code></pre>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-11-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>&gt; 
&gt; rm(i, j, p2, gcur)</code></pre>
</div>
<div id="resistance-and-amu-over-time" class="section level2">
<h2>Resistance and AMU over time</h2>
<p>We plot the observed resistance (red dots) for each cycle.</p>
<p>AMU (only colistin and all antibotics) is represented as colored bars. We can plot the qualitative use (yes/no each week) (<code>amu_quanti=F</code>), or the quantitative use (amount per kg of chicken each week) (<code>amu_quanti=T</code>). In the latter case, we fix a ceiling, i.e. a maximum of the quantity plotted: this is to avoid one large AMU measure preventing to observe lower quantities on the graph. This ceiling is determined by <code>ratio_resmet_quanti_amu</code> which is the ratio between the maximum value of the resistance metric, and the maximum value of the AMU <strong>on the plot</strong> (no consequence on the values in the analysis).</p>
<pre class="r"><code>&gt; amu_quanti = F
&gt; ratio_resmet_quanti_amu = 50</code></pre>
<pre class="r"><code>&gt; obs_plot = rbind(data.frame(cyc=rep(NA, n_cyc*n_weeks), week=rep(NA, n_cyc*n_weeks), obser=rep(NA, n_cyc*n_weeks), exp_ab=rep(NA, n_cyc*n_weeks), type_ab=rep(&quot;Colistin&quot;, n_cyc*n_weeks)),
+                  data.frame(cyc=rep(NA, n_cyc*n_weeks), week=rep(NA, n_cyc*n_weeks), obser=rep(NA, n_cyc*n_weeks), exp_ab=rep(NA, n_cyc*n_weeks), type_ab=rep(&quot;All antibiotics&quot;, n_cyc*n_weeks)))
&gt; 
&gt; obs_plot$cyc = as.vector(matrix(rep(rownames(res_data),n_weeks), n_weeks, n_cyc, byrow=T))
&gt; obs_plot$week = rep(seq(1,n_weeks),n_cyc)
&gt; 
&gt; for (f in rownames(res_data)){
+   n_weeks_cyc = sum(!(is.na(col_expo[f,])))
+   samp_cyc = which(!(is.na(res_data[f,])))
+   
+   if(length(samp_cyc) &lt; 2){print(paste0(&quot;CAUTION: For cycle &quot;, f,&quot;, the number of samples collected is strictly less than 2&quot;))}
+ 
+   obs_plot$obser[which((obs_plot$cyc==f) &amp; (obs_plot$week %in% weeks_samp[f,samp_cyc]))] = as.numeric(res_data[f,samp_cyc])
+   
+   if(amu_quanti){
+     obs_plot$exp_ab[which((obs_plot$cyc == f) &amp; (obs_plot$type_ab == &quot;Colistin&quot;))] = col_expo_quanti[f,]
+     obs_plot$exp_ab[which((obs_plot$cyc == f) &amp; (obs_plot$type_ab == &quot;All antibiotics&quot;))] = allab_expo_quanti[f,]
+ 
+   }else{
+     obs_plot$exp_ab[which((obs_plot$cyc == f) &amp; (obs_plot$type_ab == &quot;Colistin&quot;))] = col_expo[f,]
+     obs_plot$exp_ab[which((obs_plot$cyc == f) &amp; (obs_plot$type_ab == &quot;All antibiotics&quot;))] = allab_expo[f,]
+   }
+ }
&gt; 
&gt; if(amu_quanti){
+   obs_plot$exp_ab[which(obs_plot$exp_ab &gt; (max(res_data, na.rm=T) * ratio_resmet_quanti_amu))] = max(res_data, na.rm=T) * ratio_resmet_quanti_amu
+ }
&gt; 
&gt; obs_plot$cyc = factor(obs_plot$cyc, levels=rownames(res_data))
&gt; 
&gt; # Plot:
&gt; 
&gt; p = ggplot(data=obs_plot[which(obs_plot$cyc %in% rownames(res_data)),], aes(x=week))
&gt; p = p + xlab(&quot;Time (weeks)&quot;)
&gt; p = p + ylab(&quot;Resistance metric&quot;)
&gt; 
&gt; if(amu_quanti){
+   
+   p = p + ggtitle(&quot;Quantitative AMU and colistin resistance in each cycle&quot;)
+   p = p + geom_bar(aes(y=exp_ab/ratio_resmet_quanti_amu, fill=type_ab), stat=&quot;identity&quot;, position=&quot;dodge2&quot;, col=NA)
+   
+   p = p + scale_y_continuous(sec.axis = sec_axis(~.*ratio_resmet_quanti_amu, name = paste0(&quot;AMU (mg/kg) (ceiling &quot;, round(max(res_data, na.rm=T) * ratio_resmet_quanti_amu), &quot; mg/kg for each type)&quot;)))
+   p = p + theme(axis.text.y.right = element_text(color=&quot;blue&quot;), axis.title.y.right = element_text(color=&quot;blue&quot;))
+ 
+ }else{
+   
+   p = p + ggtitle(&quot;Qualitative AMU and colistin resistance in each cycle&quot;)
+   p = p + geom_bar(aes(y=exp_ab/2, fill=type_ab), stat=&quot;identity&quot;, position=&quot;stack&quot;, col=NA)
+ }
&gt; 
&gt; p = p +  scale_fill_discrete(name = &quot;Antibiotics used:&quot;)
&gt; p = p + geom_point(aes(y = obser), size = 3, shape = 21,  fill = &quot;red&quot;, color = &quot;black&quot;)
&gt; p = p + facet_wrap(~ cyc)
&gt; p</code></pre>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-13-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>&gt; 
&gt; rm(f, n_weeks_cyc, samp_cyc, far, iter_list, p, pl, ratio_resmet_quanti_amu, obs_plot, amu_quanti, n_weeks)</code></pre>
</div>
<div id="resistance-plotted-versus-different-amu-metrics-in-shiny" class="section level2">
<h2>Resistance plotted versus different AMU metrics in Shiny</h2>
<p>This function is useful to:</p>
<ul>
<li>Show an interactive Shiny plot (<code>obj="plot"</code>) (not shown in the regular html)</li>
<li>The further estimation of our model (<code>obj="est"</code>), as it returns the observed resistance and AMU, depending on the value of some parameters</li>
</ul>
<pre class="r"><code>&gt; 
&gt; resamu = function(nwkseff, quantuse=T, tempo_amu=&quot;exp_decay&quot;, thresh_res, ignore.nul=F, lag_amu_init, obj=&quot;plot&quot;, expo){
+   obtab = data.frame(cycle=NA, amu_init=NA, amu_t=NA, obsres=NA, age=NA, init=NA, prev=NA, end=NA)
+   for(cyc_i in 1:n_cyc){
+     for(time_i in 2:3){
+       
+       first_amu_week_consid = weeks_samp[cyc_i, time_i] - nwkseff
+       last_amu_week_consid = weeks_samp[cyc_i, time_i] - 1
+       
+       if(expo == &quot;allab&quot;){
+         use_quali = allab_expo
+         use_quanti = allab_expo_quanti
+       }else if(expo == &quot;col&quot;){
+         use_quali = col_expo
+         use_quanti = col_expo_quanti
+       }
+       
+       if(tempo_amu %in% c(&quot;step&quot;, &quot;linear&quot;)){
+         inc_wks = max(1, first_amu_week_consid):last_amu_week_consid
+       }else if(tempo_amu == &quot;exp_decay&quot;){
+         inc_wks = 1:last_amu_week_consid
+       }
+       
+       amu_t = rep(0, last_amu_week_consid)
+       if(quantuse){
+         amu_t[inc_wks] = use_quanti[cyc_i, inc_wks]
+       }else{
+         amu_t[inc_wks] = use_quali[cyc_i, inc_wks]
+       }
+ 
+       if(tempo_amu == &quot;linear&quot;){
+         time_eff = seq(0, 1, length.out = nwkseff+1)[-1]
+         amu_t[inc_wks] = amu_t[inc_wks] * time_eff
+       }else if(tempo_amu == &quot;exp_decay&quot;){
+         time_eff = (exp(-log(100)/nwkseff))^(rev(inc_wks)-1)
+         amu_t = amu_t * time_eff
+       }
+       
+       amu_t = sum(amu_t)
+       
+       if(lag_amu_init &gt; last_amu_week_consid){
+         lag_amu_init = last_amu_week_consid
+       }
+       amu_init = c(use_quanti[cyc_i, (1:floor(lag_amu_init))], (lag_amu_init - floor(lag_amu_init)) * use_quanti[cyc_i, ceiling(lag_amu_init)])
+       
+       amu_init = sum(amu_init)
+       
+       obtab = rbind(obtab, c(cyc_i, amu_init, amu_t, res_data[cyc_i, time_i], weeks_samp[cyc_i, time_i], res_data[cyc_i, 1], res_data[cyc_i, time_i-1], time_i==3))
+     }
+   }
+   obtab = obtab[-1,]
+   
+   if(ignore.nul){
+     obtab = obtab[which((obtab$amu_init + obtab$amu_t) != 0),]
+   }
+   obtab$cycle = as.factor(obtab$cycle)
+   
+   obtab$res = obtab$obsres &gt;= thresh_res
+ 
+   if(obj == &quot;plot&quot;){
+     p = ggplot(data=obtab, aes(x=amu_t, y=obsres, col=init))
+     p = p + xlab(&quot;Recent AMU&quot;) + ylab(&quot;Measure of resistance&quot;)
+     p = p + ggtitle(paste0(&quot;Pearson correlation between recent AMU and the measure of resistance: &quot;, round(cor(obtab$amu_t, obtab$obsres, use=&quot;complete.obs&quot;), 3)))
+     p = p + geom_point()
+     p = p + geom_hline(yintercept = thresh_res, linetype=&quot;dashed&quot;, col=&quot;grey&quot;)
+     p = p + scale_color_gradient(low = &quot;red&quot;, high = &quot;blue&quot;)
+     # p = ggplotly(p)
+     return(p)
+   }else if(obj == &quot;est&quot;){
+     return(obtab)
+   }
+ }</code></pre>
<p>Here, either we run an interactive Shiny app, or we plot a simple graph showing on the y-axis the measured resistance, and on the x-axis the AMU (qualitative, all classes) in the last 3 days before each sampling, with an exponential decay of the effect of antibiotics. The color is the value of resistance in the initial sample of the production cycle (week 1). This is to observe the graphical association between resistance and AMU, and the group of observations for which resistance is high but AMU is low. For the last ones, we want to test if this high resistance could be explained by introductions.</p>
<pre class="r"><code>&gt; ui &lt;- fluidPage({
+   titlePanel(&quot;Correlation between past use and the measure of resistance&quot;)
+   sidebarLayout(
+     sidebarPanel(
+       sliderInput(&quot;nwkseff&quot;,
+                   paste0(&quot;Number of weeks of past use to take into account (beta):&quot;),
+                   min=1,
+                   max=25,
+                   value=3),
+       sliderInput(&quot;lag_amu_init&quot;,
+                   &quot;Number of first weeks of the cycle with permanent effect of use (delta):&quot;,
+                   min=1,
+                   max=15,
+                   value=3),
+       sliderInput(&quot;thresh_res&quot;,
+                   &quot;Threshold value for the measure of resistance:&quot;,
+                   min=0,
+                   max=1,
+                   value=0.5),
+       selectInput(&quot;tempo_amu&quot;,
+                   &quot;Temporal effect of AMU:&quot;,
+                   c(&quot;exp_decay&quot;, &quot;linear&quot;, &quot;step&quot;)),
+       selectInput(&quot;expo&quot;,
+                   &quot;AMU is all antibiotics (allab) or only colistin (col):&quot;,
+                   c(&quot;allab&quot;, &quot;col&quot;)),
+       selectInput(&quot;quantuse&quot;,
+                   &quot;Select if the quantitative AMU should be used:&quot;,
+                   c(T, F)),
+       selectInput(&quot;ignore.nul&quot;,
+                   &quot;Select if the nul values of use should be ignored:&quot;,
+                   c(T, F))
+     ),
+     
+     mainPanel(
+       plotOutput(&quot;plotdisp&quot;)
+     )
+   )
+ })
&gt; 
&gt; server &lt;- function(input, output){
+   # define the output, the output id must be the same with the ID in the UI object
+   # because the output change as the input change - it&#39;s dynamic so we need a special function renderPlot() to make the output react with our choice
+   
+   output$plotdisp &lt;- renderPlot({
+     # filter the data by the input and save into new object
+     # the input id must be the same as the UI object
+     # plot
+     resamu(nwkseff=input$nwkseff, lag_amu_init=input$lag_amu_init, expo=input$expo, quantuse=input$quantuse, tempo_amu=input$tempo_amu, thresh_res=input$thresh_res, ignore.nul=input$ignore.nul)
+   })
+ }
&gt; 
&gt; run_shiny = F
&gt; if(run_shiny){
+   shinyApp(ui=ui, server=server)
+ }else{
+   resamu(nwkseff = 1.00001, quantuse = F, tempo_amu=&quot;exp_decay&quot;, thresh_res = 0.5, lag_amu_init = 1, obj=&quot;plot&quot;, expo=&quot;col&quot;)
+ }
Warning: Removed 1 rows containing missing values (geom_point).</code></pre>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>&gt; rm(ui, server, run_shiny)</code></pre>
</div>
</div>
<div id="analysis" class="section level1">
<h1>Analysis</h1>
<div id="model-and-expectation-maximization-algorithm" class="section level2">
<h2>Model and Expectation-Maximization algorithm</h2>
<p>The introduction of colistin resistant bacteria from outside the flock is not measured but can potentially play an important role in the resistance of the sample. We consider a latent (unobserved) binary variable to describe if an introduction happened in the farm (yes/no).</p>
<p>We use an Expectation-Maximization (E-M) algorithm with 2 steps:</p>
<ul>
<li>Expectation: given a set of parameters, determine the most likely status for introduction (yes/no) for each observation.</li>
<li>Maximization: given an assumed introduction status, determine the set of parameters maximizing the likelihood of the model.</li>
</ul>
<p>The algorithm is initiated with a random set of parameters, and is terminated when a convergence of likelihood is reached.</p>
<p>For all observations in the 2nd or 3rd round of samplings, we define a model used in the Maximization step. Several models are tested, all being simplified versions of this full model:</p>
<p><span class="math display">\[R_i(t) = \sum_{k \in \{ t_1 ; t_2 \} }(\lambda_k.R_i(k)) + \eta.f_i(t) + \alpha.A_{recent,i}(t) + \theta.A_{init,i}(t) + \mu\]</span> where:</p>
<ul>
<li><span class="math inline">\(R_i(t)\)</span> is the measure of resistance in observation (sample) i</li>
<li><span class="math inline">\(t\)</span> is the week the sample was collected</li>
<li><span class="math inline">\(R_i(t_1)\)</span> is the measure of resistance in the initial sample of the same flock</li>
<li><span class="math inline">\(R_i(t_2)\)</span> is the measure of resistance in the previous sample if the observation belongs to the 3rd round of sampling (autocorrelation)</li>
<li><span class="math inline">\(f_i(t)=1\)</span> if an introduction occurred before the sampling (between <span class="math inline">\(t-\xi\)</span> and <span class="math inline">\(t-1\)</span>, where <span class="math inline">\(\xi\)</span> is fixed at 4 weeks), and <span class="math inline">\(f(t)=0\)</span> otherwise</li>
<li><span class="math inline">\(\mu\)</span> is the average resistance when all other variables are null.</li>
</ul>
<p>The AMU metric <span class="math inline">\(A_{recent,i}(t)\)</span> is the use that just precedes the sampling date, and is defined as:</p>
<p><span class="math display">\[A_{recent,i}(t)=\sum_{j=1}^{t-1}(U(j).exp[\frac{ln(\epsilon)}{\beta}.(t-j-1)])\]</span></p>
<p>where <span class="math inline">\(U(j)\)</span> is the (quantitative or qualitative) antimicrobial use in the flock on week j. For now, in the following, we consider only qualitative use (= 0 or 1).</p>
<p>As shown in the figure below, <span class="math inline">\(A_{recent,i}(t)\)</span> is parametrized as an exponential decay: after β+1 weeks, the effect of AMU is <span class="math inline">\(\epsilon\)</span> (&lt;&lt; 1) times its effect after one week. We fix <span class="math inline">\(\epsilon\)</span> at 1%.</p>
<p><span class="math inline">\(A_{init,i}(t)\)</span> is the use that occurs at the begining of the cycle (first <span class="math inline">\(\delta\)</span> weeks). It is uncertain if it has effect on the resistance during the whole production cycle. We test this hypothesis. It is defined as:</p>
<p><span class="math display">\[A_{init,i}(t)=\sum_{j=1}^{\delta}U(j)\]</span></p>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>If <code>definition_amu = "col"</code>, the use is defined as the qualitative colistin use. If <code>definition_amu = "allab"</code>, the use is defined as the qualitative use of any antibiotic.</p>
<pre class="r"><code>&gt; definition_amu = &quot;col&quot;</code></pre>
</div>
<div id="variations-of-the-model" class="section level2">
<h2>Variations of the model</h2>
<p>The full model described above is model 24. Models 1 to 23 are simplifications of model 24.</p>
<table>
<thead>
<tr class="header">
<th align="center">Models</th>
<th align="center">Previous resistance</th>
<th align="center">AMU</th>
<th align="center">Introductions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>1</strong></td>
<td align="center">None</td>
<td align="center">None</td>
<td align="center">None</td>
</tr>
<tr class="even">
<td align="center"><strong>2</strong></td>
<td align="center">Initial</td>
<td align="center">None</td>
<td align="center">None</td>
</tr>
<tr class="odd">
<td align="center"><strong>3</strong></td>
<td align="center">Initial + Previous</td>
<td align="center">None</td>
<td align="center">None</td>
</tr>
<tr class="even">
<td align="center"><strong>4</strong></td>
<td align="center">None</td>
<td align="center">Initial</td>
<td align="center">None</td>
</tr>
<tr class="odd">
<td align="center"><strong>5</strong></td>
<td align="center">Initial</td>
<td align="center">Initial</td>
<td align="center">None</td>
</tr>
<tr class="even">
<td align="center"><strong>6</strong></td>
<td align="center">Initial + Previous</td>
<td align="center">Initial</td>
<td align="center">None</td>
</tr>
<tr class="odd">
<td align="center"><strong>7</strong></td>
<td align="center">None</td>
<td align="center">Recent</td>
<td align="center">None</td>
</tr>
<tr class="even">
<td align="center"><strong>8</strong></td>
<td align="center">Initial</td>
<td align="center">Recent</td>
<td align="center">None</td>
</tr>
<tr class="odd">
<td align="center"><strong>9</strong></td>
<td align="center">Initial + Previous</td>
<td align="center">Recent</td>
<td align="center">None</td>
</tr>
<tr class="even">
<td align="center"><strong>10</strong></td>
<td align="center">None</td>
<td align="center">Initial + Recent</td>
<td align="center">None</td>
</tr>
<tr class="odd">
<td align="center"><strong>11</strong></td>
<td align="center">Initial</td>
<td align="center">Initial + Recent</td>
<td align="center">None</td>
</tr>
<tr class="even">
<td align="center"><strong>12</strong></td>
<td align="center">Initial + Previous</td>
<td align="center">Initial + Recent</td>
<td align="center">None</td>
</tr>
<tr class="odd">
<td align="center"><strong>13</strong></td>
<td align="center">None</td>
<td align="center">None</td>
<td align="center">Possible</td>
</tr>
<tr class="even">
<td align="center"><strong>14</strong></td>
<td align="center">Initial</td>
<td align="center">None</td>
<td align="center">Possible</td>
</tr>
<tr class="odd">
<td align="center"><strong>15</strong></td>
<td align="center">Initial + Previous</td>
<td align="center">None</td>
<td align="center">Possible</td>
</tr>
<tr class="even">
<td align="center"><strong>16</strong></td>
<td align="center">None</td>
<td align="center">Initial</td>
<td align="center">Possible</td>
</tr>
<tr class="odd">
<td align="center"><strong>17</strong></td>
<td align="center">Initial</td>
<td align="center">Initial</td>
<td align="center">Possible</td>
</tr>
<tr class="even">
<td align="center"><strong>18</strong></td>
<td align="center">Initial + Previous</td>
<td align="center">Initial</td>
<td align="center">Possible</td>
</tr>
<tr class="odd">
<td align="center"><strong>19</strong></td>
<td align="center">None</td>
<td align="center">Recent</td>
<td align="center">Possible</td>
</tr>
<tr class="even">
<td align="center"><strong>20</strong></td>
<td align="center">Initial</td>
<td align="center">Recent</td>
<td align="center">Possible</td>
</tr>
<tr class="odd">
<td align="center"><strong>21</strong></td>
<td align="center">Initial + Previous</td>
<td align="center">Recent</td>
<td align="center">Possible</td>
</tr>
<tr class="even">
<td align="center"><strong>22</strong></td>
<td align="center">None</td>
<td align="center">Initial + Recent</td>
<td align="center">Possible</td>
</tr>
<tr class="odd">
<td align="center"><strong>23</strong></td>
<td align="center">Initial</td>
<td align="center">Initial + Recent</td>
<td align="center">Possible</td>
</tr>
<tr class="even">
<td align="center"><strong>24</strong></td>
<td align="center">Initial + Previous</td>
<td align="center">Initial + Recent</td>
<td align="center">Possible</td>
</tr>
</tbody>
</table>
</div>
<div id="useful-functions" class="section level2">
<h2>Useful functions</h2>
<div id="function-returning-the-minus-loglikelihood" class="section level3">
<h3>Function returning the minus loglikelihood</h3>
<p>This function enters the raw (transformed) values of the model’s parameters and the probability of introduction for each observation, and returns either the minus loglikelihood (<code>aim="est"</code>), or the predicted and observed values of resistance and AMU, the minus loglikelihood and the true (not transformed) values of parameters (<code>aim="pred"</code>).</p>
<p>Observations for which the resistance measure (model outcome) is absent are deleted. However, if an observation has NA values for measure of resistance in previous samples (<code>obsdat$init</code> and <code>obsdat$prev</code>), the value is set at the mean of the other values.</p>
<p>We also define <code>run2_intr</code> which is a wraper: its output is the function <code>run2</code> with the value of <code>intr</code> (input of <code>run2</code>) specified.</p>
<pre class="r"><code>&gt; run2 = function(aim=&quot;est&quot;, intr=introd, distrib_res=&quot;normal&quot;, mu, lambda1, lambda2, alpha, beta, teta, delta, eta, Sd){
+ 
+   mu = sigmoid(mu)
+   lambda1 = lambda1
+   lambda2 = lambda2
+   alpha = alpha
+   beta = 10 * sigmoid(beta) +1
+   teta = teta
+   delta = 5 * sigmoid(delta) +1
+   eta = sigmoid(eta)
+   Sd = 3 * sigmoid(Sd)
+ 
+   obsdat = resamu(nwkseff=beta, quantuse=F, tempo_amu=&quot;exp_decay&quot;, thresh_res=0.4, ignore.nul=F, lag_amu_init=delta, obj=&quot;est&quot;, expo=definition_amu)
+   obsdat = obsdat[! is.na(obsdat$obsres),]
+   obsdat$init[is.na(obsdat$init)] = mean(obsdat$init, na.rm=T) # 0
+   obsdat$prev[is.na(obsdat$prev)] = mean(obsdat$prev, na.rm=T) # 0
+   obsdat$introduc = intr
+ 
+   obsdat$predmod_intro = mu + lambda1 * obsdat$init + (lambda2 * obsdat$prev)*as.numeric(obsdat$end) + alpha * obsdat$amu_t + teta * obsdat$amu_init + eta
+   
+   obsdat$predmod_nointro = mu + lambda1 * obsdat$init + (lambda2 * obsdat$prev)*as.numeric(obsdat$end) + alpha * obsdat$amu_t + teta * obsdat$amu_init
+   
+   obsdat$predmod = obsdat$introduc * obsdat$predmod_intro + (1-obsdat$introduc) * obsdat$predmod_nointro
+ 
+   if(aim == &quot;est&quot;){
+     if(distrib_res == &quot;normal&quot;){
+       lik_intro = dnorm(x=obsdat$obsres, mean=obsdat$predmod_intro, sd=Sd)
+       lik_nointro = dnorm(x=obsdat$obsres, mean=obsdat$predmod_nointro, sd=Sd)
+       
+       total_loglik = log(obsdat$introduc * lik_intro + (1-obsdat$introduc) * lik_nointro)
+       total_loglik[is.infinite(total_loglik)] = -710
+ 
+       return(-sum(total_loglik))
+       
+     }else{
+       print(&quot;Residuals distribution not defined.&quot;)
+     }
+   }else if (aim == &quot;pred&quot;){
+     return(list(obsdat = obsdat[,c(&quot;obsres&quot;, &quot;amu_init&quot;, &quot;amu_t&quot;, &quot;introduc&quot;, &quot;predmod&quot;, &quot;cycle&quot;)], minll = -sum(dnorm(x=obsdat$obsres, mean=obsdat$predmod, sd=Sd, log=T)), true_param = c(mu, lambda1, lambda2, alpha, beta, teta, delta, eta, Sd)))
+   }
+ }
&gt; 
&gt; # Factory/Wrapper function (returns a function with one of the parameters (&quot;intr&quot;) fixed)
&gt; run2_intr &lt;- function(x) {
+  function(aim=&quot;est&quot;, distrib_res=&quot;normal&quot;, mu, lambda1, lambda2, alpha, beta, teta, delta, eta, Sd)
+    run2(aim, intr=x, distrib_res, mu, lambda1, lambda2, alpha, beta, teta, delta, eta, Sd)
+ }</code></pre>
</div>
<div id="function-plotting-a-models-fit" class="section level3">
<h3>Function plotting a model’s fit</h3>
<p>This function takes as input the fitted model, and returns a plot with one dot per observation: the observed resistance on x-axis, the predicted resistance on y-axis.</p>
<pre class="r"><code>&gt; fitplot = function(fitted_model, intro){
+   fit_coef = coef(fitted_model)
+   
+   obs_vs_pred = run2(aim=&quot;pred&quot;, intr=intro, mu=fit_coef[&quot;mu&quot;], lambda1=fit_coef[&quot;lambda1&quot;], lambda2=fit_coef[&quot;lambda2&quot;], alpha=fit_coef[&quot;alpha&quot;], beta=fit_coef[&quot;beta&quot;], teta=fit_coef[&quot;teta&quot;], delta=fit_coef[&quot;delta&quot;], eta=fit_coef[&quot;eta&quot;], Sd=fit_coef[&quot;Sd&quot;])
+   
+   minll = obs_vs_pred[[2]]
+   print(paste(&quot;Minus LogLikelihood:&quot;, minll))
+   
+   true_fit_coef = obs_vs_pred[[3]]
+   print(&quot;True values of parameters:&quot;)
+   print(true_fit_coef)
+   
+   p = ggplot(obs_vs_pred[[1]], aes(x = obsres, y = predmod, fill = true_fit_coef[&quot;alpha&quot;]*amu_t + true_fit_coef[&quot;teta&quot;]*amu_init, col = introduc))
+   p = p + xlab(&quot;Observed resistance&quot;) + ylab(&quot;Predicted resistance&quot;)
+   p = p + ggtitle(paste0(&quot;Observed VS Predicted resistance (minus LogLikelihood =&quot;, round(minll, 2), &quot;)&quot;))
+   p = p + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;)
+   p = p + geom_point(shape = 21, size = 3)
+   p = p + labs(col = &quot;Probability of introduction (outline):&quot;, fill = &quot;Global AMU metric (interior color):&quot;)
+   p = p + scale_colour_gradient(low = &quot;green&quot;, high = &quot;red&quot;)
+   p = p + scale_fill_gradient(low = &quot;white&quot;, high = &quot;blue&quot;)
+   p
+ }</code></pre>
</div>
<div id="example-of-estimation-of-the-full-model-for-one-given-introduction-status" class="section level3">
<h3>Example of estimation of the full model for one given introduction status</h3>
<p>Here, we test the full model’s estimation (M-step on model 24), with one given introduction status for each observation. We use “bbmle” package for point estimates.</p>
<pre class="r"><code>&gt; introd = c(rep(0, 4), 1, 0, 1, 1, 1, rep(0, 6), 1, 0, 1, rep(0, 3), 1, 0, 0, 1, rep(0, 7), 1, 0, 0, 1, 1, 1, 0, 1, rep(0, 5), 1, rep(0, 3))
&gt; 
&gt; fit_mle2 = mle2(minuslogl = run2_intr(introd), method = &quot;Nelder-Mead&quot;, control = list(maxit = 5000), start = list(mu = logit(runif(1)), lambda1 = runif(1), lambda2 = runif(1), alpha = runif(1), beta = logit(runif(1)), teta = runif(1), delta = logit(runif(1)), eta = logit(runif(1)), Sd = logit(runif(1))))
&gt; 
&gt; fitplot(fitted_model = fit_mle2, intro = introd)
[1] &quot;Minus LogLikelihood: 7.51012458537352&quot;
[1] &quot;True values of parameters:&quot;
           mu       lambda1       lambda2         alpha          beta          teta         delta           eta            Sd 
 0.3983820835 -0.0320280887 -0.1170565918  0.2345845857  1.9812614137 -0.0002168066  5.6848602672  0.1179153023  0.2796583690 </code></pre>
<p><img src="Analysis_col_res_files/figure-html/Test%20full%20model%20estimation-1.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code>&gt; rm(introd, fit_mle2)</code></pre>
</div>
<div id="function-repeating-the-fit-several-times" class="section level3">
<h3>Function repeating the fit several times</h3>
<p>This function repeats the model’s fit process several times, to make sure the maximum of likelihood is not only local. Among repetitions, the model with the highest likelihood is the one chosen by the function.</p>
<p>The function takes as inputs the model’s parameters that should be fixed (not estimated), and those that should be estimated. This is to adapt to the different variations of the model (see above). Some parameters are transformed to be estimated in an interval.</p>
<p>It is made such that the random initialization of parameters is different from one repetition to another.</p>
<pre class="r"><code>&gt; rep_est = function(nrep, minusloglrep, methodrep, controlrep, fixedvar, startvar){
+   modrep = list()
+   for(repet in 1:nrep){
+     cat(&quot;\r&quot;, paste0(&quot;Fit repetition &quot;, repet, &quot;/&quot;, nrep))
+     
+     valpar = list(mu=NULL, lambda1=NULL, lambda2=NULL, alpha=NULL, beta=NULL, teta=NULL, delta=NULL, eta=NULL, Sd=NULL)
+     valpar[fixedvar] = 0
+     valpar[startvar] = runif(length(startvar))
+     valpar[c(&quot;mu&quot;, &quot;beta&quot;, &quot;delta&quot;, &quot;eta&quot;, &quot;Sd&quot;)] = lapply(X = valpar[c(&quot;mu&quot;, &quot;beta&quot;, &quot;delta&quot;, &quot;eta&quot;, &quot;Sd&quot;)], FUN = logit)
+     
+     modrep[[repet]] = mle2(minuslogl=minusloglrep, method=methodrep, control=controlrep, fixed=valpar[fixedvar], start=valpar[startvar])
+   }
+   loglikrep = lapply(X=modrep, FUN=logLik)
+   
+   cat(&quot;\n&quot;)
+   
+   modrep[[which.max(loglikrep)]]
+ }</code></pre>
</div>
<div id="implementation-of-the-full-e-m-algorithm" class="section level3">
<h3>Implementation of the full E-M algorithm</h3>
<div id="function-for-the-e-step" class="section level4">
<h4>Function for the E step</h4>
<p>With one given set of parameters for the model, we determine what is the most likely probability for the occurrence of an introduction in the flock, for each observation.</p>
<p>We first calculate the residuals <span class="math inline">\(r_{intro}^i\)</span> (<code>r_intro</code>) and <span class="math inline">\(r_{nointro}^i\)</span> (<code>r_nointro</code>) of observations <span class="math inline">\(R_i\)</span> (observed resistance) under the 2 models: <span class="math inline">\(M_{intro}\)</span> (“Only introductions”) and <span class="math inline">\(M_{nointro}\)</span> (“No introduction”).</p>
<p>The idea is to compute, for each observation, the probability that it is assigned to each of the 2 models:</p>
<p><span class="math display">\[p(R_i \in M_{intro}) = \frac{p(r_{intro}^i/R_i \in M_{intro})}{p(r_{intro}^i/R_i \in M_{intro}) + p(r_{nointro}^i/R_i \in M_{nointro})}\]</span></p>
<p>And:</p>
<p><span class="math display">\[p(R_i \in M_{nointro}) = 1-p(R_i \in M_{intro})\]</span></p>
<p>As the residuals follow a normal distribution (with mean=0 and standard deviation <span class="math inline">\(\sigma\)</span> (<code>sigma</code>), estimated in the M-step):</p>
<p><span class="math display">\[p(R_i \in M_{intro}) = \frac{exp(\frac{-(r_{intro}^i)^2}{2.\sigma^2})}{exp(\frac{-(r_{intro}^i)^2}{2.\sigma^2}) + exp(\frac{-(r_{nointro}^i)^2}{2.\sigma^2})}\]</span></p>
<p>(Sources: <a href="http://www.cs.huji.ac.il/~yweiss/emTutorial.pdf" class="uri">http://www.cs.huji.ac.il/~yweiss/emTutorial.pdf</a> ; <a href="http://www.di.fc.ul.pt/~jpn/r/EM/EM.html#eg-em-with-mix-of-two-linear-models" class="uri">http://www.di.fc.ul.pt/~jpn/r/EM/EM.html#eg-em-with-mix-of-two-linear-models</a>)</p>
<pre class="r"><code>&gt; E_step &lt;- function(observed, params) {
+ 
+   sigma = 3 * sigmoid(params[[&quot;Sd&quot;]]) # because the parameter is modified when estimated in function &quot;run2&quot;
+   
+   lin_intro = run2(aim=&quot;pred&quot;, intr=1, mu=params[[&quot;mu&quot;]], lambda1=params[[&quot;lambda1&quot;]], lambda2=params[[&quot;lambda2&quot;]], alpha=params[[&quot;alpha&quot;]], beta=params[[&quot;beta&quot;]], teta=params[[&quot;teta&quot;]], delta=params[[&quot;delta&quot;]], eta=params[[&quot;eta&quot;]], Sd=params[[&quot;Sd&quot;]])[[&quot;obsdat&quot;]]$predmod
+   
+   lin_nointro = run2(aim=&quot;pred&quot;, intr=0, mu=params[[&quot;mu&quot;]], lambda1=params[[&quot;lambda1&quot;]], lambda2=params[[&quot;lambda2&quot;]], alpha=params[[&quot;alpha&quot;]], beta=params[[&quot;beta&quot;]], teta=params[[&quot;teta&quot;]], delta=params[[&quot;delta&quot;]], eta=params[[&quot;eta&quot;]], Sd=params[[&quot;Sd&quot;]])[[&quot;obsdat&quot;]]$predmod
+ 
+   # Residuals of observations under models &quot;Intro&quot; and &quot;No intro&quot;
+   r_intro = abs(lin_intro - observed)
+   r_nointro = abs(lin_nointro - observed)
+ 
+   # Residuals follow a normal distribution
+   exp_intro = exp(- r_intro^2/(2*sigma^2))
+   exp_nointro = exp(- r_nointro^2/(2*sigma^2))
+ 
+   exp_intro = pmin(0.9999, exp_intro)
+   exp_intro = pmax(0.0001, exp_intro)
+   exp_nointro = pmin(0.9999, exp_nointro)
+   exp_nointro = pmax(0.0001, exp_nointro)
+ 
+   # Probability of &quot;Intro&quot;:
+   prob_intro = exp_intro / (exp_intro + exp_nointro)
+ 
+   prob_intro
+ }</code></pre>
</div>
<div id="function-for-the-m-step" class="section level4">
<h4>Function for the M step</h4>
<p>Given a probability of introduction for each observation, we fit the model. Depending on the model, some parameters can be fixed in the <code>mle2</code> function. Several repetitions of the fit are computed, with function <code>rep_est</code>.</p>
<p>The likelihood is defined as:</p>
<p><span class="math display">\[L(\Theta|R_1,...,R_i,...) = \prod_{i}(p(R_i \in M_{intro}).L(\Theta|R_i,R_i \in M_{intro}) + p(R_i \in M_{nointro}).L(\Theta|R_i,R_i \in M_{nointro}))\]</span></p>
<pre class="r"><code>&gt; M_step &lt;- function(introd, modnum) {
+ 
+   prop_intro = mean(introd)
+   
+   #####
+   if(modnum == 13){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda1&quot;,  &quot;lambda2&quot;,  &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;), startvar = c(&quot;mu&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 14){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda2&quot;,  &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 15){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;lambda2&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 16){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda1&quot;,  &quot;lambda2&quot;,  &quot;alpha&quot;,  &quot;beta&quot;), startvar = c(&quot;mu&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 17){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda2&quot;,  &quot;alpha&quot;,  &quot;beta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 18){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;alpha&quot;,  &quot;beta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;lambda2&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 19){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda1&quot;,  &quot;lambda2&quot;,  &quot;teta&quot;,  &quot;delta&quot;), startvar = c(&quot;mu&quot;,  &quot;alpha&quot;,  &quot;beta&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 20){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda2&quot;,  &quot;teta&quot;,  &quot;delta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;alpha&quot;,  &quot;beta&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 21){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;teta&quot;,  &quot;delta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;lambda2&quot;,  &quot;alpha&quot;,  &quot;beta&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 22){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda1&quot;,  &quot;lambda2&quot;), startvar = c(&quot;mu&quot;,  &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 23){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda2&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }else if(modnum == 24){
+     modstep = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c(), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;lambda2&quot;,  &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;, &quot;Sd&quot;))
+   }
+   #####
+   
+   raw_coef = coef(modstep)
+   ob_pred = run2(aim=&quot;pred&quot;, intr=introd, mu=raw_coef[&quot;mu&quot;], lambda1=raw_coef[&quot;lambda1&quot;], lambda2=raw_coef[&quot;lambda2&quot;], alpha=raw_coef[&quot;alpha&quot;], beta=raw_coef[&quot;beta&quot;], teta=raw_coef[&quot;teta&quot;], delta=raw_coef[&quot;delta&quot;], eta=raw_coef[&quot;eta&quot;], Sd=raw_coef[&quot;Sd&quot;])
+   
+   raw_coef = c(raw_coef, p_intro = prop_intro)
+   llmod = ob_pred[[2]]
+   true_coef = ob_pred[[3]]
+   number_cycle = ob_pred[[1]]$cycle
+   
+   list(raw_coef, llmod, modstep, true_coef, number_cycle)
+ }</code></pre>
</div>
<div id="function-to-launch-the-whole-algorithm" class="section level4">
<h4>Function to launch the whole algorithm</h4>
<p>We repeat the algorithm several times to make sure the whole space has been explored.</p>
<p>Convergence is defined as: the distance between the likelihood and the former likelihood is less than 1, 3 times in a row.</p>
<pre class="r"><code>&gt; EM_algo &lt;- function(modnum, numb_rep_algo=3, tol=1, max.step=50) {
+ 
+   repetalgo = list()
+   repetalgo_minloglik = c()
+   
+   for(algorep_ite in 1:numb_rep_algo){
+     print(paste0(&quot;##### Model &quot;, modnum, &quot; (repetition &quot;, algorep_ite, &quot;/&quot;, numb_rep_algo, &quot; of the algorithm) #####&quot;)); cat(&quot;\n&quot;)
+     
+     step = 0
+     minloglik = 10^6
+     
+     raw_params = list(mu = logit(runif(1)), lambda1 = runif(1), lambda2 = runif(1), alpha = runif(1), beta = logit(runif(1)), teta = runif(1), delta = logit(runif(1)), eta = logit(runif(1)), Sd = logit(runif(1)), p_intro = runif(1))
+     
+     obs_res = resamu(obj=&quot;est&quot;, nwkseff=1, thresh_res=0.5, lag_amu_init=1, expo=definition_amu)$obsres
+     obs_res = obs_res[! is.na(obs_res)]
+ 
+     counting_for_convergence = 0
+     while((counting_for_convergence &lt;3) &amp; (step &lt;= max.step+1)){
+       step = step +1
+       if(step == max.step+1){
+         print(paste0(&quot;Convergence of the likelihood was not reached after &quot;, max.step, &quot; steps.&quot;))
+         break
+       }
+       
+       print(paste0(&quot;Step: &quot;, step))
+       introductions = E_step(observed=obs_res, params=raw_params)
+       output_mstep = M_step(introd=introductions, modnum)
+       raw_params = output_mstep[[1]]
+       old.minloglik = minloglik
+       minloglik = output_mstep[[2]]
+       print(paste0(&quot;Minus Log Likelihood: &quot;, minloglik))
+       modstep = output_mstep[[3]]
+       param_true_format = output_mstep[[4]]
+       cycle_id = output_mstep[[5]]
+   
+       if (abs(minloglik - old.minloglik) &lt; tol){
+         counting_for_convergence = counting_for_convergence +1
+       }else{
+         counting_for_convergence = 0
+       }
+     }
+     print(paste0(&quot;Final step: &quot;, step)); cat(&quot;\n&quot;)
+     
+     if(step == max.step+1){write.table(c(), file=paste0(&quot;C:/Users/Jonathan/Desktop/Model &quot;, modnum, &quot;, iteration &quot;, algorep_ite, &quot; ouf of &quot;, numb_rep_algo, &quot; - no convergence of the likelihood&quot;))}
+     
+     repetalgo[[algorep_ite]] = list(modstep, raw_params, introductions, minloglik, param_true_format, number_obs=length(obs_res), cycle_id)
+     repetalgo_minloglik[algorep_ite] = minloglik
+   }
+   
+   save(repetalgo, file = paste0(&quot;C:/Users/Jonathan/Desktop/resul_&quot;, definition_amu, &quot;_mod_&quot;, modnum, &quot;.rdata&quot;))
+ 
+   repetalgo[[which.min(repetalgo_minloglik)]]
+ }</code></pre>
</div>
</div>
<div id="test-of-the-e-m-algorithm-on-simulated-data" class="section level3">
<h3>Test of the E-M algorithm on simulated data</h3>
<p>From the real AMU data, we want to create fake data of resistance showing a clear relationship between use and resistance. We also want to add fake introductions above this. This is to test the ability of the algorithm to detect an effect of the recent AMU on resistance, along with introductions.</p>
<p>First, we save the true resistance data:</p>
<pre class="r"><code>&gt; res_data_saved = res_data</code></pre>
<p>We create fake resistance data such that the relationship with AMU is linear, with <span class="math inline">\(\beta_{fake} = 8\)</span> (<code>beta_fake</code>) and <span class="math inline">\(\alpha_{fake} = 0.4\)</span> (<code>alpha_fake</code>). Note that we add some noise.</p>
<pre class="r"><code>&gt; beta_fake = 8
&gt; alpha_fake = 0.4
&gt; 
&gt; fake_res = run2(aim=&quot;pred&quot;, intr=0, mu=logit(0.05), lambda1=0, lambda2=0, alpha=alpha_fake, beta=logit((beta_fake-1)/10), teta=0, delta=1, eta=0, Sd=0.1)[[&quot;obsdat&quot;]]$predmod
&gt; fake_res = fake_res + rnorm(length(fake_res), 0, 0.05)
&gt; 
&gt; res_data = as.data.frame(cbind(res_data$S, matrix(c(fake_res[1:40], NA, fake_res[41:49]), nrow=length(res_data$S), ncol=2, byrow=T)))
&gt; 
&gt; resamu(nwkseff = 8, quantuse=F, thresh_res = 0.5, lag_amu_init = 1, expo=definition_amu)
Warning: Removed 1 rows containing missing values (geom_point).</code></pre>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-26-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Now we add some introductions in observations with low AMU, to simulate the fact observations with low AMU have sometimes a high resistance:</p>
<pre class="r"><code>&gt; introd_fake = sample(x = which(fake_res &lt; 0.2), size = round(0.5 * length(which(fake_res &lt; 0.2))))
&gt; fake_res[introd_fake] = fake_res[introd_fake] + rnorm(length(introd_fake), 0.5, 0.05)
&gt; 
&gt; res_data = res_data_saved
&gt; res_data = as.data.frame(cbind(res_data$S, matrix(c(fake_res[1:40], NA, fake_res[41:49]), nrow=length(res_data$S), ncol=2, byrow=T)))
&gt; 
&gt; resamu(nwkseff = 8, quantuse=F, thresh_res = 0.5, lag_amu_init = 1, expo=definition_amu)
Warning: Removed 1 rows containing missing values (geom_point).</code></pre>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-27-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Therefore, we are in a situation where the fake resistance data was simulated by model 19 (introductions + recent AMU). We want to test now if the algorithm can detect the relationship between AMU and fake resistance data. We also want to know if model 19 is selected against model 13 (introductions only).</p>
<p>We apply the algorithm on model 13:</p>
<pre class="r"><code>&gt; results_mod13 = EM_algo(modnum=13, numb_rep_algo=1)
[1] &quot;##### Model 13 (repetition 1/1 of the algorithm) #####&quot;

[1] &quot;Step: 1&quot;

 Fit repetition 1/5
 Fit repetition 2/5
 Fit repetition 3/5
 Fit repetition 4/5
 Fit repetition 5/5
[1] &quot;Minus Log Likelihood: 82.6780079510708&quot;
[1] &quot;Step: 2&quot;

 Fit repetition 1/5
 Fit repetition 2/5
 Fit repetition 3/5
 Fit repetition 4/5
 Fit repetition 5/5
[1] &quot;Minus Log Likelihood: -42.6589690411321&quot;
[1] &quot;Step: 3&quot;

 Fit repetition 1/5
 Fit repetition 2/5
 Fit repetition 3/5
 Fit repetition 4/5
 Fit repetition 5/5
[1] &quot;Minus Log Likelihood: -42.3621594792093&quot;
[1] &quot;Step: 4&quot;

 Fit repetition 1/5
 Fit repetition 2/5
 Fit repetition 3/5
 Fit repetition 4/5
 Fit repetition 5/5
[1] &quot;Minus Log Likelihood: -42.3552677770188&quot;
[1] &quot;Step: 5&quot;

 Fit repetition 1/5
 Fit repetition 2/5
 Fit repetition 3/5
 Fit repetition 4/5
 Fit repetition 5/5
[1] &quot;Minus Log Likelihood: -42.3566987213531&quot;
[1] &quot;Final step: 5&quot;
&gt; fitplot(fitted_model = results_mod13[[1]], intro = results_mod13[[3]])
[1] &quot;Minus LogLikelihood: -42.3566987213531&quot;
[1] &quot;True values of parameters:&quot;
        mu    lambda1    lambda2      alpha       beta       teta      delta        eta         Sd 
0.09048672 0.00000000 0.00000000 0.00000000 1.00000000 0.00000000 1.00000000 0.50720886 0.11367058 </code></pre>
<p><img src="Analysis_col_res_files/figure-html/E-M%20algorithm%20on%20fake%20resistance%20data%20(model%2013)-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>And we apply the algorithm on model 19:</p>
<pre class="r"><code>&gt; results_mod19 = EM_algo(modnum=19, numb_rep_algo=1)
[1] &quot;##### Model 19 (repetition 1/1 of the algorithm) #####&quot;

[1] &quot;Step: 1&quot;

 Fit repetition 1/5
 Fit repetition 2/5
 Fit repetition 3/5
 Fit repetition 4/5
 Fit repetition 5/5
[1] &quot;Minus Log Likelihood: 418.573598497122&quot;
[1] &quot;Step: 2&quot;

 Fit repetition 1/5
 Fit repetition 2/5
 Fit repetition 3/5
 Fit repetition 4/5
 Fit repetition 5/5
[1] &quot;Minus Log Likelihood: -67.6303359476515&quot;
[1] &quot;Step: 3&quot;

 Fit repetition 1/5
 Fit repetition 2/5
 Fit repetition 3/5
 Fit repetition 4/5
 Fit repetition 5/5
[1] &quot;Minus Log Likelihood: -67.6264266545753&quot;
[1] &quot;Step: 4&quot;

 Fit repetition 1/5
 Fit repetition 2/5
 Fit repetition 3/5
 Fit repetition 4/5
 Fit repetition 5/5
[1] &quot;Minus Log Likelihood: -67.6327484356601&quot;
[1] &quot;Step: 5&quot;

 Fit repetition 1/5
 Fit repetition 2/5
 Fit repetition 3/5
 Fit repetition 4/5
 Fit repetition 5/5
[1] &quot;Minus Log Likelihood: -67.6307791399479&quot;
[1] &quot;Final step: 5&quot;
&gt; fitplot(fitted_model = results_mod19[[1]], intro = results_mod19[[3]])
[1] &quot;Minus LogLikelihood: -67.6307791399479&quot;
[1] &quot;True values of parameters:&quot;
        mu    lambda1    lambda2      alpha       beta       teta      delta        eta         Sd 
0.03790715 0.00000000 0.00000000 0.39893382 8.32348336 0.00000000 1.00000000 0.55359812 0.05982420 </code></pre>
<p><img src="Analysis_col_res_files/figure-html/E-M%20algorithm%20on%20fake%20resistance%20data%20(model%2019)-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The fit seems good. Let us compare both models’ AIC:</p>
<pre class="r"><code>&gt; print(&quot;AIC of model 13:&quot;)
[1] &quot;AIC of model 13:&quot;
&gt; AIC(results_mod13[[1]]) + results_mod13[[&quot;number_obs&quot;]]
[1] -18.4112
&gt; 
&gt; print(&quot;AIC of model 19:&quot;)
[1] &quot;AIC of model 19:&quot;
&gt; AIC(results_mod19[[1]]) + results_mod19[[&quot;number_obs&quot;]]
[1] -77.8762</code></pre>
<p>The algorithm detects the relationship between use and fake resistance, and model 19 has a lower AIC than model 13.</p>
<p>We delete the fake resistance data and come back to the true data:</p>
<pre class="r"><code>&gt; res_data = res_data_saved
&gt; 
&gt; rm(res_data_saved, results_mod13, results_mod19, beta_fake, alpha_fake, fake_res, introd_fake)</code></pre>
</div>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<p>If the computation was already performed, <code>alread_comp = T</code>.</p>
<pre class="r"><code>&gt; alread_comp = T</code></pre>
<div id="estimation-of-models-1-to-12-without-introduction" class="section level3">
<h3>Estimation of models 1 to 12 without introduction</h3>
<p>First, we fit models that do not take into account the introductions. For them, we do not need to implement the E-M algorithm. Because the package <code>bbmle</code> does not always find the likelihood maximum, we repeat the estimation 10 times with <code>rep_est</code>, and take the maximum likelihood among these repetitions. The list <code>lfit</code> contains all fitted models.</p>
<pre class="r"><code>&gt; 
&gt; if(alread_comp){
+   load(paste0(&quot;C:/Users/Jonathan/Desktop/Resultats simulations/colistin_resistance/&quot;, definition_amu, &quot; - Qualitative - Exp/lfit_&quot;, definition_amu,&quot;.rdata&quot;))
+ }else{
+   introd = 0
+   lfit = list()
+   
+   lfit[[1]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c(&quot;lambda1&quot;, &quot;lambda2&quot;, &quot;alpha&quot;, &quot;beta&quot;, &quot;teta&quot;, &quot;delta&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;, &quot;Sd&quot;))
+   
+   lfit[[2]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda2&quot;,  &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;, &quot;Sd&quot;))
+   
+   lfit[[3]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;lambda2&quot;, &quot;Sd&quot;))
+   
+   lfit[[4]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c(&quot;lambda1&quot;, &quot;lambda2&quot;, &quot;alpha&quot;, &quot;beta&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;, &quot;teta&quot;, &quot;delta&quot;, &quot;Sd&quot;))
+   
+   lfit[[5]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda2&quot;,  &quot;alpha&quot;,  &quot;beta&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;Sd&quot;))
+   
+   lfit[[6]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;alpha&quot;,  &quot;beta&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;lambda2&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;Sd&quot;))
+   
+   lfit[[7]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda1&quot;,  &quot;lambda2&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;,  &quot;alpha&quot;,  &quot;beta&quot;, &quot;Sd&quot;))
+   
+   lfit[[8]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda2&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;alpha&quot;,  &quot;beta&quot;, &quot;Sd&quot;))
+   
+   lfit[[9]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;teta&quot;,  &quot;delta&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;lambda2&quot;,  &quot;alpha&quot;,  &quot;beta&quot;, &quot;Sd&quot;))
+   
+   lfit[[10]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda1&quot;,  &quot;lambda2&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;,  &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;Sd&quot;))
+   
+   lfit[[11]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c( &quot;lambda2&quot;, &quot;eta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;Sd&quot;))
+   
+   lfit[[12]] = rep_est(nrep=5, minusloglrep = run2_intr(introd), methodrep = &quot;Nelder-Mead&quot;, controlrep = list(maxit = 5000), fixedvar = c(&quot;eta&quot;), startvar = c(&quot;mu&quot;,  &quot;lambda1&quot;,  &quot;lambda2&quot;,  &quot;alpha&quot;,  &quot;beta&quot;,  &quot;teta&quot;,  &quot;delta&quot;, &quot;Sd&quot;))
+   
+   rm(introd)
+ }</code></pre>
</div>
<div id="parallel-computation-of-the-e-m-algorithm-for-models-13-to-24" class="section level3">
<h3>Parallel computation of the E-M algorithm for models 13 to 24</h3>
<p>We repeat the algorithm 5 times (with different seeds) per model, and each maximization step (model fit) is repeated 5 times (with different seeds too) to make sure the likelihood maximum is reached.</p>
<pre class="r"><code>&gt; 
&gt; if(alread_comp){
+   load(paste0(&quot;C:/Users/Jonathan/Desktop/Resultats simulations/colistin_resistance/&quot;, definition_amu, &quot; - Qualitative - Exp/resulpar_&quot;, definition_amu, &quot;_all.rdata&quot;))
+ }else{
+   t = as.numeric(Sys.time())
+ 
+   cl&lt;-makeCluster(7)
+   clusterEvalQ(cl, list(library(pracma), library(bbmle)))
+   clusterExport(cl, c(&quot;definition_amu&quot;,&quot;E_step&quot;,&quot;M_step&quot;,&quot;rep_est&quot;,&quot;run2&quot;,&quot;run2_intr&quot;,&quot;resamu&quot;,&quot;n_cyc&quot;,&quot;res_data&quot;,&quot;weeks_samp&quot;,&quot;col_expo&quot;,&quot;col_expo_quanti&quot;,&quot;allab_expo&quot;,&quot;allab_expo_quanti&quot;))
+   resulpar_13to21 = parLapply(cl, X=13:21, fun=EM_algo, numb_rep_algo=3)
+   stopCluster(cl)
+   save(resulpar_13to21, file = paste0(&quot;C:/Users/Jonathan/Desktop/resulpar_&quot;, definition_amu, &quot;_13to21.rdata&quot;))
+   
+   cl&lt;-makeCluster(3)
+   clusterEvalQ(cl, list(library(pracma), library(bbmle)))
+   clusterExport(cl, c(&quot;definition_amu&quot;,&quot;E_step&quot;,&quot;M_step&quot;,&quot;rep_est&quot;,&quot;run2&quot;,&quot;run2_intr&quot;,&quot;resamu&quot;,&quot;n_cyc&quot;,&quot;res_data&quot;,&quot;weeks_samp&quot;,&quot;col_expo&quot;,&quot;col_expo_quanti&quot;,&quot;allab_expo&quot;,&quot;allab_expo_quanti&quot;))
+   resulpar_22to24 = parLapply(cl, X=22:24, fun=EM_algo, numb_rep_algo=3)
+   stopCluster(cl)
+   save(resulpar_22to24, file = paste0(&quot;C:/Users/Jonathan/Desktop/resulpar_&quot;, definition_amu, &quot;_22to24.rdata&quot;))
+   
+   resulpar = c(resulpar_13to21, resulpar_22to24)
+   save(resulpar, file = paste0(&quot;C:/Users/Jonathan/Desktop/resulpar_&quot;, definition_amu, &quot;_all.rdata&quot;))
+ 
+   as.numeric(Sys.time()) - t
+   
+   for(m in 1:12){lfit[[m+12]] = resulpar[[m]][[1]]}
+   save(lfit, file = paste0(&quot;C:/Users/Jonathan/Desktop/lfit_&quot;, definition_amu, &quot;.rdata&quot;))
+   rm(m, cl)
+ }
&gt; 
&gt; rm(alread_comp)</code></pre>
</div>
<div id="comparison-of-the-models" class="section level3">
<h3>Comparison of the models</h3>
<p>The list <code>lfit</code> contains the 24 fitted models. We compare and plot their loglikelihood and AIC weights (= probability that each model is the best).</p>
<p>The AIC weight <span class="math inline">\(W_k\)</span> of a model <span class="math inline">\(k\)</span> is defined as:</p>
<p><span class="math display">\[ W_k = \frac{e^{-\frac{1}{2}.(AIC_k-min(AIC))}}{\sum_{j=1}^{24}(e^{-\frac{1}{2}.(AIC_j-min(AIC))})}\]</span> where <span class="math inline">\(N\)</span> is the total number of models, and <span class="math inline">\(AIC_k\)</span> is the AIC of model <span class="math inline">\(k\)</span>.</p>
<pre class="r"><code>&gt; l_loglik = unlist(lapply(X = lfit, FUN = logLik))
&gt; l_aic = unlist(lapply(X = lfit, FUN = AIC))
&gt; l_aic[13:24] = l_aic[13:24] + resulpar[[1]][[&quot;number_obs&quot;]]
&gt; 
&gt; l_aic_weights = exp(-(l_aic - min(l_aic))/2) / sum(exp(-(l_aic - min(l_aic))/2))
&gt; 
&gt; tab_aic_ll = data.frame(mod = as.factor(1:24), LogLikelihood = l_loglik, MinAIC = -l_aic, AIC_weights = l_aic_weights)
&gt; plot_aic_ll = melt(tab_aic_ll, id = &quot;mod&quot;)
&gt; 
&gt; p = ggplot(data = plot_aic_ll, aes(y = mod))
&gt; p = p + ggtitle(&quot;Comparison of the fitted models&quot;) + xlab(&quot;Indicator value&quot;) + ylab(&quot;Models&quot;)
&gt; p = p + geom_vline(data = subset(plot_aic_ll, variable == &quot;LogLikelihood&quot;), aes(xintercept = max(plot_aic_ll$value[plot_aic_ll$variable == &quot;LogLikelihood&quot;])), linetype = &quot;dashed&quot;)
&gt; p = p + geom_vline(data = subset(plot_aic_ll, variable == &quot;MinAIC&quot;), aes(xintercept = max(plot_aic_ll$value[plot_aic_ll$variable == &quot;MinAIC&quot;])), linetype = &quot;dashed&quot;)
&gt; p = p + geom_vline(data = subset(plot_aic_ll, variable == &quot;AIC_weights&quot;), aes(xintercept = max(plot_aic_ll$value[plot_aic_ll$variable == &quot;AIC_weights&quot;])), linetype = &quot;dashed&quot;)
&gt; p = p + geom_point(aes(x = value), shape=18, size=2)
&gt; p = p + facet_wrap(~variable, scales = &quot;free_x&quot;)
&gt; p = ggplotly(p)
&gt; p</code></pre>
<div id="htmlwidget-6abcf37db2ecbe7777e8" style="width:768px;height:576px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-6abcf37db2ecbe7777e8">{"x":{"data":[{"x":[39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495,39.4427702589495],"y":[0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6],"text":"max(plot_aic_ll$value[plot_aic_ll$variable == \"LogLikelihood\"]): 39.44277","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087,19.4995573354087],"y":[0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6],"text":"max(plot_aic_ll$value[plot_aic_ll$variable == \"MinAIC\"]): 19.49956","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x2","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125,0.500041284854125],"y":[0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6,24.6],"text":"max(plot_aic_ll$value[plot_aic_ll$variable == \"AIC_weights\"]): 0.5000413","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x3","yaxis":"y","hoverinfo":"text","frame":null},{"x":[-15.1051467167766,-15.0044784278484,-14.761949365561,-15.0737249408357,-14.996769594784,-14.738938178071,-13.2332198976209,-12.9532000727083,-12.9448554842806,-13.5533128196654,-12.9549970855184,-13.7777555157514,35.3429410363851,35.3691321456998,36.1702185578531,36.5285833849892,37.0736560227439,36.9434805667255,39.2497786677044,39.2434357969658,39.4427702589495,38.6216882053396,38.298049207264,38.294387823735],"y":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"text":["value: -1.510515e+01<br />mod: 1","value: -1.500448e+01<br />mod: 2","value: -1.476195e+01<br />mod: 3","value: -1.507372e+01<br />mod: 4","value: -1.499677e+01<br />mod: 5","value: -1.473894e+01<br />mod: 6","value: -1.323322e+01<br />mod: 7","value: -1.295320e+01<br />mod: 8","value: -1.294486e+01<br />mod: 9","value: -1.355331e+01<br />mod: 10","value: -1.295500e+01<br />mod: 11","value: -1.377776e+01<br />mod: 12","value:  3.534294e+01<br />mod: 13","value:  3.536913e+01<br />mod: 14","value:  3.617022e+01<br />mod: 15","value:  3.652858e+01<br />mod: 16","value:  3.707366e+01<br />mod: 17","value:  3.694348e+01<br />mod: 18","value:  3.924978e+01<br />mod: 19","value:  3.924344e+01<br />mod: 20","value:  3.944277e+01<br />mod: 21","value:  3.862169e+01<br />mod: 22","value:  3.829805e+01<br />mod: 23","value:  3.829439e+01<br />mod: 24"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(0,0,0,1)","opacity":1,"size":7.55905511811024,"symbol":"diamond","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[-34.2102934335532,-36.0089568556969,-37.5238987311219,-38.1474498816715,-39.993539189568,-41.477876356142,-34.4664397952417,-35.9064001454166,-37.8897109685612,-39.1066256393308,-39.9099941710368,-43.5555110315029,15.6858820727703,13.7382642913996,13.3404371157061,14.0571667699784,13.1473120454879,10.886961133451,19.4995573354087,17.4868715939316,15.8855405178989,14.2433764106792,11.5960984145281,9.58877564747009],"y":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"text":["value: -3.421029e+01<br />mod: 1","value: -3.600896e+01<br />mod: 2","value: -3.752390e+01<br />mod: 3","value: -3.814745e+01<br />mod: 4","value: -3.999354e+01<br />mod: 5","value: -4.147788e+01<br />mod: 6","value: -3.446644e+01<br />mod: 7","value: -3.590640e+01<br />mod: 8","value: -3.788971e+01<br />mod: 9","value: -3.910663e+01<br />mod: 10","value: -3.990999e+01<br />mod: 11","value: -4.355551e+01<br />mod: 12","value:  1.568588e+01<br />mod: 13","value:  1.373826e+01<br />mod: 14","value:  1.334044e+01<br />mod: 15","value:  1.405717e+01<br />mod: 16","value:  1.314731e+01<br />mod: 17","value:  1.088696e+01<br />mod: 18","value:  1.949956e+01<br />mod: 19","value:  1.748687e+01<br />mod: 20","value:  1.588554e+01<br />mod: 21","value:  1.424338e+01<br />mod: 22","value:  1.159610e+01<br />mod: 23","value:  9.588776e+00<br />mod: 24"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(0,0,0,1)","opacity":1,"size":7.55905511811024,"symbol":"diamond","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x2","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1.08657561919911e-012,4.42064007568887e-013,2.07262011183882e-013,1.51746015426701e-013,6.02898351469032e-014,2.87028073448321e-014,9.55957269928594e-013,4.6532358264699e-013,1.72617407590528e-013,9.39366194121476e-014,6.28616341334536e-014,1.01571470158906e-014,0.0742808391398108,0.0280515571197131,0.0229916373163331,0.0329007476358348,0.0208753287634731,0.00674224235856478,0.500041284854125,0.182791798855237,0.082079004748638,0.0361110965714609,0.00961150870870198,0.00352295392436999],"y":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"text":["value:  1.086576e-12<br />mod: 1","value:  4.420640e-13<br />mod: 2","value:  2.072620e-13<br />mod: 3","value:  1.517460e-13<br />mod: 4","value:  6.028984e-14<br />mod: 5","value:  2.870281e-14<br />mod: 6","value:  9.559573e-13<br />mod: 7","value:  4.653236e-13<br />mod: 8","value:  1.726174e-13<br />mod: 9","value:  9.393662e-14<br />mod: 10","value:  6.286163e-14<br />mod: 11","value:  1.015715e-14<br />mod: 12","value:  7.428084e-02<br />mod: 13","value:  2.805156e-02<br />mod: 14","value:  2.299164e-02<br />mod: 15","value:  3.290075e-02<br />mod: 16","value:  2.087533e-02<br />mod: 17","value:  6.742242e-03<br />mod: 18","value:  5.000413e-01<br />mod: 19","value:  1.827918e-01<br />mod: 20","value:  8.207900e-02<br />mod: 21","value:  3.611110e-02<br />mod: 22","value:  9.611509e-03<br />mod: 23","value:  3.522954e-03<br />mod: 24"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(0,0,0,1)","opacity":1,"size":7.55905511811024,"symbol":"diamond","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x3","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":54.9649923896499,"r":7.30593607305936,"b":39.6955859969559,"l":37.2602739726027},"plot_bgcolor":"rgba(235,235,235,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"title":{"text":"Comparison of the fitted models","font":{"color":"rgba(0,0,0,1)","family":"","size":17.5342465753425},"x":0,"xref":"paper"},"xaxis":{"domain":[0,0.32976598173516],"automargin":true,"type":"linear","autorange":false,"range":[-17.8325425655629,42.1701661077358],"tickmode":"array","ticktext":["0","20","40"],"tickvals":[0,20,40],"categoryorder":"array","categoryarray":["0","20","40"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":"","hoverformat":".2f"},"annotations":[{"text":"Indicator value","x":0.5,"y":-0.0147450532724505,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"top","annotationType":"axis"},{"text":"Models","x":-0.0110587899543379,"y":0.5,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xref":"paper","yref":"paper","textangle":-90,"xanchor":"right","yanchor":"center","annotationType":"axis"},{"text":"LogLikelihood","x":0.16488299086758,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":11.689497716895},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"MinAIC","x":0.5,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":11.689497716895},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"AIC_weights","x":0.83511700913242,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":11.689497716895},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"}],"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.4,24.6],"tickmode":"array","ticktext":["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24"],"tickvals":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"categoryorder":"array","categoryarray":["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":"","hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":0.32976598173516,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.66417600664176,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":0.32976598173516,"y0":0,"y1":23.37899543379,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.336900684931507,"x1":0.663099315068493,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.66417600664176,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.336900684931507,"x1":0.663099315068493,"y0":0,"y1":23.37899543379,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.67023401826484,"x1":1,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.66417600664176,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.67023401826484,"x1":1,"y0":0,"y1":23.37899543379,"yanchor":1,"ysizemode":"pixel"}],"xaxis2":{"type":"linear","autorange":false,"range":[-46.7082644498484,22.6523107537543],"tickmode":"array","ticktext":["-40","-20","0","20"],"tickvals":[-40,-20,0,20],"categoryorder":"array","categoryarray":["-40","-20","0","20"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.336900684931507,0.663099315068493],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":"","hoverformat":".2f"},"xaxis3":{"type":"linear","autorange":false,"range":[-0.0250020642426956,0.525043349096831],"tickmode":"array","ticktext":["0.0","0.1","0.2","0.3","0.4","0.5"],"tickvals":[0,0.1,0.2,0.3,0.4,0.5],"categoryorder":"array","categoryarray":["0.0","0.1","0.2","0.3","0.4","0.5"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.67023401826484,1],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":"","hoverformat":".2f"},"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false},"source":"A","attrs":{"17fc6bc51d5d":{"xintercept":{},"type":"scatter"},"17fc29432446":{"xintercept":{}},"17fc292b1be":{"xintercept":{}},"17fc5f572ab5":{"x":{},"y":{}}},"cur_data":"17fc6bc51d5d","visdat":{"17fc6bc51d5d":["function (y) ","x"],"17fc29432446":["function (y) ","x"],"17fc292b1be":["function (y) ","x"],"17fc5f572ab5":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>&gt; 
&gt; rm(p, plot_aic_ll, l_loglik, l_aic)</code></pre>
<p>Model 19 has the highest AIC weights (= lowest AIC). We plot its fit (observed VS predicted):</p>
<pre class="r"><code>&gt; 
&gt; fitplot(fitted_model = resulpar[[7]][[1]], intro = resulpar[[7]][[3]])
[1] &quot;Minus LogLikelihood: -42.2205012855657&quot;
[1] &quot;True values of parameters:&quot;
        mu    lambda1    lambda2      alpha       beta       teta      delta        eta         Sd 
0.08953509 0.00000000 0.00000000 0.13731039 1.00003689 0.00000000 1.00000000 0.60345863 0.10827543 </code></pre>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-32-1.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code>&gt; print(paste0(&quot;Probability of introduction in model 19: &quot;, resulpar[[7]][[2]][[&quot;p_intro&quot;]]))
[1] &quot;Probability of introduction in model 19: 0.473735370794441&quot;</code></pre>
<p>To compare the contributions of variables, we apply this methodology:</p>
<p>For instance, to compare the contributions of variables V1, V2 and V3, we start by comparing the null model (model 1) to the model with V1 only (resp. V2 only and V3 only). Between V1, V2 and V3, the most contributing variable is the one for which the AIC weights ratio with model 1 is the highest, e.g. V3. We also perform a likelihood ratio test between the null model and, in this case, the model with V3 only. Then, we compare the model with V3 only with the model including V3 and V2 (resp. V3 and V1). Between V1 and V2, the second most contributing variable is the one that maximize the AIC weights ratio. Similarly, a likelihood ratio test is performed to test the gain of adding this second variable. At each step, the AIC weights ratio has to be higher than 1, to demonstrate a higher probability of being the best model.</p>
<p>Therefore, we first compare these ratios: [AIC weights of models 2, 4, 7 and 13] / [AIC weights of model 1]:</p>
<pre class="r"><code>&gt; print(tab_aic_ll$AIC_weights[2] /tab_aic_ll$AIC_weights[1])
[1] 0.4068415
&gt; print(tab_aic_ll$AIC_weights[4] /tab_aic_ll$AIC_weights[1])
[1] 0.1396553
&gt; print(tab_aic_ll$AIC_weights[7] /tab_aic_ll$AIC_weights[1])
[1] 0.879789
&gt; print(tab_aic_ll$AIC_weights[13] /tab_aic_ll$AIC_weights[1])
[1] 68362328242</code></pre>
<p>The first contributing factor seems to be the introductions.</p>
<pre class="r"><code>&gt; bbmle::anova(lfit[[1]], lfit[[13]])
Likelihood Ratio Tests
Model 1: lfit[[1]], [minusloglrep]: mu+Sd
Model 2: lfit[[13]], [minusloglrep]: mu+eta+Sd
  Tot Df Deviance Chisq Df Pr(&gt;Chisq)    
1      2   30.210                        
2      3  -70.686 100.9  1  &lt; 2.2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The likelihood ratio test is significant.</p>
<p>Next step is compare these ratios: [AIC weights of models 14, 16 and 19] / [AIC weights of model 13]:</p>
<pre class="r"><code>&gt; print(tab_aic_ll$AIC_weights[14] /tab_aic_ll$AIC_weights[13])
[1] 0.3776419
&gt; print(tab_aic_ll$AIC_weights[16] /tab_aic_ll$AIC_weights[13])
[1] 0.4429237
&gt; print(tab_aic_ll$AIC_weights[19] /tab_aic_ll$AIC_weights[13])
[1] 6.731767</code></pre>
<p>The second most contributing variable seems to be the recent AMU.</p>
<pre class="r"><code>&gt; bbmle::anova(lfit[[13]], lfit[[19]])
Likelihood Ratio Tests
Model 1: lfit[[13]], [minusloglrep]: mu+eta+Sd
Model 2: lfit[[19]], [minusloglrep]: mu+alpha+beta+eta+Sd
  Tot Df Deviance  Chisq Df Pr(&gt;Chisq)  
1      3  -70.686                       
2      5  -78.500 7.8137  2     0.0201 *
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The likelihood ratio test is significant.</p>
<p>Next step is compare these ratios: [AIC weights of models 20 and 22] / [AIC weights of model 19]:</p>
<pre class="r"><code>&gt; print(tab_aic_ll$AIC_weights[20] /tab_aic_ll$AIC_weights[19])
[1] 0.3655534
&gt; print(tab_aic_ll$AIC_weights[22] /tab_aic_ll$AIC_weights[19])
[1] 0.07221623
&gt; 
&gt; bbmle::anova(lfit[[19]], lfit[[20]])
Likelihood Ratio Tests
Model 1: lfit[[19]], [minusloglrep]: mu+alpha+beta+eta+Sd
Model 2: lfit[[20]], [minusloglrep]: mu+lambda1+alpha+beta+eta+Sd
  Tot Df Deviance  Chisq Df Pr(&gt;Chisq)
1      5  -78.500                     
2      6  -78.487 0.0127  1     0.9103
&gt; bbmle::anova(lfit[[19]], lfit[[22]])
Likelihood Ratio Tests
Model 1: lfit[[19]], [minusloglrep]: mu+alpha+beta+eta+Sd
Model 2: lfit[[22]], [minusloglrep]: mu+alpha+beta+teta+delta+eta+Sd
  Tot Df Deviance  Chisq Df Pr(&gt;Chisq)
1      5  -78.500                     
2      7  -77.243 1.2562  2     0.5336</code></pre>
<p>In conclusion, model 19 (introductions + recent AMU) seems to explain best the data (highest AIC weight). With the LRT, it is not significant to add variables to complexify model 19.</p>
<p>The most important factor explaining the level of colistin resistance measured in the farms is therefore the introductions. The AMU (colistin) in the 1 week preceding the sampling plays a role too. On the contrary, the AMU at the beginning of the production cycle does not appear to play an important role, nor the resistance in the previous samples in the same flock (autocorrelation).</p>
</div>
<div id="spatial-autocorrelation-of-the-probability-of-introduction" class="section level3">
<h3>Spatial autocorrelation of the probability of introduction</h3>
<p>Now we computed the probability of introduction for each sample (2 per farm), we want to check if the probability of introduction is spatially autocorrelated.</p>
<p>We load the GPS data (<code>gps_farms</code>):</p>
<pre class="r"><code>&gt; gps_farms = as.data.frame(read_excel(path=&quot;C:/Users/Jonathan/Desktop/Programmes/colistin_resistance/GPS-300818.xlsx&quot;, sheet=&quot;Cycle&quot;)[,c(12,13,14)])
&gt; colnames(gps_farms) = c(&quot;Farm&quot;, &quot;Lat&quot;, &quot;Long&quot;)
&gt; gps_farms$Farm = substr(gps_farms$Farm, 4, 6)</code></pre>
<p>We gather in a same data frame the farm IDs and introduction probabilities (<code>prob_intro_farms</code>):</p>
<pre class="r"><code>&gt; prob_intro_farms = data.frame(Farm = resulpar[[7]][[7]], Prob = resulpar[[7]][[3]])
&gt; prob_intro_farms$Farm = rownames(weeks_samp)[prob_intro_farms$Farm]
&gt; prob_intro_farms$Farm = substr(prob_intro_farms$Farm, 1, 3)</code></pre>
<p>We add GPS information to <code>prob_intro_farms</code>. We plot the 2 samples of each farm slighlty shifted, to observe both of them not overlapped.</p>
<pre class="r"><code>&gt; prob_intro_farms = merge(x = prob_intro_farms, y = gps_farms, by = &quot;Farm&quot;, all.x = T)
&gt; 
&gt; p = ggplot(data = prob_intro_farms, aes(x = Long, y = Lat, col = Prob))
&gt; p = p + ggtitle(&quot;Location of the farms and their probability of introduction&quot;)
&gt; p = p + xlab(&quot;Longitude&quot;) + ylab(&quot;Latitude&quot;)
&gt; p = p + geom_jitter(width = 0.003, height = 0.003)
&gt; p</code></pre>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-40-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We compute the Moran’s I statistic, defined as:</p>
<p><span class="math display">\[I = \frac{N_{samp}\sum_{i,j}W_{i,j}(p_i-\bar{p})(p_j-\bar{p})}{\sum_{i,j}W_{i,j}\sum_{i}(p_i-\bar{p})^2}\]</span></p>
<p>where <span class="math inline">\(p_i\)</span> is the probability of introduction computed for sample <span class="math inline">\(i\)</span>, <span class="math inline">\(\bar{p}\)</span> is the mean of probabilities, and <span class="math inline">\(N_{samp}\)</span> the number of samples. <span class="math inline">\(W\)</span> is the weight matrix: the closer are samples <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, the higher is <span class="math inline">\(W_{i,j}\)</span>. We define it as follows:</p>
<p><span class="math display">\[W_{i,j} = e^{-k.D(i,j)}\]</span> where <span class="math inline">\(k\)</span> is a tuned parameter, and <span class="math inline">\(D(i,j)\)</span> is the geographical distance between farms where samples <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> were sampled. Therefore, <span class="math inline">\(W_{i,j} \le 1\)</span> and the higher k, the smaller the distance <span class="math inline">\(D(i,j)\)</span> for which <span class="math inline">\(W_{i,j}\)</span> is not negligible (<span class="math inline">\(W_{i,j} &gt; 0.05\)</span> for instance).</p>
<p>Here, we compute the Moran’s I for a range of values for <span class="math inline">\(k\)</span>. Each time, we use package <code>ape</code> to test whether the probability of introduction <span class="math inline">\(p\)</span> is spatially autocorrelated: it is significantly the case when the p-value is lower than 0.05 (red line). We plot the values of the p-value depending on the values of <span class="math inline">\(k\)</span>.</p>
<p>We also plot the maximum distance <span class="math inline">\(D(i,j)\)</span> for which <span class="math inline">\(W_{i,j} &gt; 0.05\)</span> (i.e. the maximum distance not negligible in the calculation of the statistic).</p>
<pre class="r"><code>&gt; library(ape)
Warning: package &#39;ape&#39; was built under R version 3.4.4

Attaching package: &#39;ape&#39;
The following object is masked from &#39;package:agrmt&#39;:

    consensus
&gt; 
&gt; coef_moran = function(k, decay_fun){
+   dist_geo = as.matrix(dist(x = prob_intro_farms[,c(&quot;Lat&quot;, &quot;Long&quot;)]))
+   
+   if(decay_fun == &quot;exp&quot;){
+     weight_matrix = exp(-k * dist_geo)
+   }else if(decay_fun == &quot;thresh&quot;){
+     weight_matrix = (dist_geo &lt;= k)
+   }
+   diag(weight_matrix) = 0
+   
+   res = Moran.I(x = prob_intro_farms$Prob, weight = weight_matrix)
+   
+   list(p_val = res$p.value, max_dist = max(dist_geo[weight_matrix &gt; 0.05]))
+ }
&gt; 
&gt; val_thresh = seq(0,0.23,0.001)
&gt; val_exp = 1:1000
&gt; 
&gt; plot(x = val_exp, y = sapply(X = val_exp, FUN = coef_moran, decay_fun = &quot;exp&quot;)[&quot;p_val&quot;,], type=&quot;l&quot;, main = &quot;p-value (there is spatial correlation if p&lt;0.05)&quot;, xlab = &quot;k&quot;, ylab = &quot;p-value&quot;) + lines(x = c(0, 100000), y = c(0.05, 0.05), col = &quot;red&quot;)</code></pre>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-41-1.png" width="407.736" style="display: block; margin: auto;" /></p>
<pre><code>integer(0)
&gt; 
&gt; plot(x = val_exp, y = sapply(X = val_exp, FUN = coef_moran, decay_fun = &quot;exp&quot;)[&quot;max_dist&quot;,], type=&quot;l&quot;, main = &quot;Maximum distance such as W(i,j) &gt; 0.05&quot;, xlab = &quot;k&quot;, ylab = &quot;Distance (°)&quot;) + lines(x = rep(min(val_exp[as.numeric(sapply(X = val_exp, FUN = coef_moran, decay_fun = &quot;exp&quot;)[&quot;p_val&quot;,]) &lt; 0.05]), 2), y = c(-10, 10), col = &quot;red&quot;) + lines(x = rep(max(val_exp[as.numeric(sapply(X = val_exp, FUN = coef_moran, decay_fun = &quot;exp&quot;)[&quot;p_val&quot;,]) &lt; 0.05]), 2), y = c(-10, 10), col = &quot;red&quot;)</code></pre>
<p><img src="Analysis_col_res_files/figure-html/unnamed-chunk-41-2.png" width="407.736" style="display: block; margin: auto;" /></p>
<pre><code>integer(0)
&gt; 
&gt; print(&quot;The values of k for which there is spatial autocorrelation (p-value &lt; 0.05) are:&quot;)
[1] &quot;The values of k for which there is spatial autocorrelation (p-value &lt; 0.05) are:&quot;
&gt; print(val_exp[as.numeric(sapply(X = val_exp, FUN = coef_moran, decay_fun = &quot;exp&quot;)[&quot;p_val&quot;,]) &lt; 0.05])
  [1]  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109
 [34] 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
 [67] 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175
[100] 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208
[133] 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
[166] 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274
[199] 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307
[232] 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340
[265] 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373
[298] 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406
[331] 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439
[364] 440 441 442 443 444 445 446 447 448 449 450</code></pre>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
